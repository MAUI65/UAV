[
  {
    "objectID": "tutorials/template.html",
    "href": "tutorials/template.html",
    "title": "Template (for example)",
    "section": "",
    "text": "All of nbdev’s configuration is done through a file called settings.ini which lives in the root of your repo. It’s in ConfigParser format. For example, here’s the first few lines of nbdev’s settings.ini file\n\n\n[DEFAULT]\nlib_name = nbdev\ndescription = Create delightful software with Jupyter Notebooks\ncopyright = 2020 onwards, Jeremy Howard\nkeywords = nbdev fastai jupyter notebook export\nuser = fastai\nauthor = Jeremy Howard and Hamel Husain\nauthor_email = j@fast.ai\nbranch = master\nmin_python = 3.7\n\n\nYou can create this file with nbdev_create_config (in which case you pass the settings manually), or with nbdev_new (which sets it up automatically for you from your repo settings). Here are all of nbdev’s settings (excluding the path and cfg_name parameters which decide where the config file is saved):\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nrepo\nstr\nNone\nRepo name\n\n\nbranch\nstr\nNone\nRepo default branch\n\n\nuser\nstr\nNone\nRepo username\n\n\nauthor\nstr\nNone\nPackage author’s name\n\n\nauthor_email\nstr\nNone\nPackage author’s email address\n\n\ndescription\nstr\nNone\nShort summary of the package\n\n\npath\nstr\n.\nPath to create config file\n\n\ncfg_name\nstr\nsettings.ini\nName of config file to create\n\n\nlib_name\nstr\n%(repo)s\nPackage name\n\n\ngit_url\nstr\nhttps://github.com/%(user)s/%(repo)s\nRepo URL\n\n\ncustom_sidebar\nbool_arg\nFalse\nUse a custom sidebar.yml?\n\n\nnbs_path\nPath\nnbs\nPath to notebooks\n\n\nlib_path\nPath\nNone\nPath to package root (default: repo with - replaced by _)\n\n\ndoc_path\nPath\n_docs\nPath to rendered docs\n\n\ntst_flags\nstr\nnotest\nTest flags\n\n\nversion\nstr\n0.0.1\nVersion of this release\n\n\ndoc_host\nstr\nhttps://%(user)s.github.io\nHostname for docs\n\n\ndoc_baseurl\nstr\n/%(repo)s\nBase URL for docs\n\n\nkeywords\nstr\nnbdev jupyter notebook python\nPackage keywords\n\n\nlicense\nstr\napache2\nLicense for the package\n\n\ncopyright\nstr\nNone\nCopyright for the package, defaults to ‘current_year onwards, author’\n\n\nstatus\nstr\n3\nDevelopment status PyPI classifier\n\n\nmin_python\nstr\n3.7\nMinimum Python version PyPI classifier\n\n\naudience\nstr\nDevelopers\nIntended audience PyPI classifier\n\n\nlanguage\nstr\nEnglish\nLanguage PyPI classifier\n\n\nrecursive\nbool_arg\nTrue\nInclude subfolders in notebook globs?\n\n\nblack_formatting\nbool_arg\nFalse\nFormat libraries with black?\n\n\nreadme_nb\nstr\nindex.ipynb\nNotebook to export as repo readme\n\n\ntitle\nstr\n%(lib_name)s\nQuarto website title\n\n\nallowed_metadata_keys\nstr\n\nPreserve the list of keys in the main notebook metadata\n\n\nallowed_cell_metadata_keys\nstr\n\nPreserve the list of keys in cell level metadata\n\n\njupyter_hooks\nbool_arg\nTrue\nRun Jupyter hooks?\n\n\nclean_ids\nbool_arg\nTrue\nRemove ids from plaintext reprs?\n\n\nclear_all\nbool_arg\nFalse\nRemove all cell metadata and cell outputs?\n\n\nput_version_in_init\nbool_arg\nTrue\nAdd the version to the main init.py in nbdev_export\n\n\n\n\n\nYou can customise nbdev for all repositories for your user with a ~/.config/nbdev/settings.ini file.\nIn order for Git actions to run smoothly, add requirements and dev_requirements with required packages in settings.ini.\nsee here as a reference."
  },
  {
    "objectID": "tutorials/index.html",
    "href": "tutorials/index.html",
    "title": "Tutorials",
    "section": "",
    "text": "Click through to any of these tutorials to get started with UAV’s features.\n\n\n\n\n\n\n\n\n\n\nTitle\n\n\nDescription\n\n\n\n\n\n\nAPI Walkthrough\n\n\nA step-by-step guide to using nbdev\n\n\n\n\nTemplate (for example)\n\n\nThe nbdev configuration file\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "explanations/template_01.html",
    "href": "explanations/template_01.html",
    "title": "Template (for example)",
    "section": "",
    "text": "All of nbdev’s configuration is done through a file called settings.ini which lives in the root of your repo. It’s in ConfigParser format. For example, here’s the first few lines of nbdev’s settings.ini file\n\n\n[DEFAULT]\nlib_name = nbdev\ndescription = Create delightful software with Jupyter Notebooks\ncopyright = 2020 onwards, Jeremy Howard\nkeywords = nbdev fastai jupyter notebook export\nuser = fastai\nauthor = Jeremy Howard and Hamel Husain\nauthor_email = j@fast.ai\nbranch = master\nmin_python = 3.7\n\n\nYou can create this file with nbdev_create_config (in which case you pass the settings manually), or with nbdev_new (which sets it up automatically for you from your repo settings). Here are all of nbdev’s settings (excluding the path and cfg_name parameters which decide where the config file is saved):\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nrepo\nstr\nNone\nRepo name\n\n\nbranch\nstr\nNone\nRepo default branch\n\n\nuser\nstr\nNone\nRepo username\n\n\nauthor\nstr\nNone\nPackage author’s name\n\n\nauthor_email\nstr\nNone\nPackage author’s email address\n\n\ndescription\nstr\nNone\nShort summary of the package\n\n\npath\nstr\n.\nPath to create config file\n\n\ncfg_name\nstr\nsettings.ini\nName of config file to create\n\n\nlib_name\nstr\n%(repo)s\nPackage name\n\n\ngit_url\nstr\nhttps://github.com/%(user)s/%(repo)s\nRepo URL\n\n\ncustom_sidebar\nbool_arg\nFalse\nUse a custom sidebar.yml?\n\n\nnbs_path\nPath\nnbs\nPath to notebooks\n\n\nlib_path\nPath\nNone\nPath to package root (default: repo with - replaced by _)\n\n\ndoc_path\nPath\n_docs\nPath to rendered docs\n\n\ntst_flags\nstr\nnotest\nTest flags\n\n\nversion\nstr\n0.0.1\nVersion of this release\n\n\ndoc_host\nstr\nhttps://%(user)s.github.io\nHostname for docs\n\n\ndoc_baseurl\nstr\n/%(repo)s\nBase URL for docs\n\n\nkeywords\nstr\nnbdev jupyter notebook python\nPackage keywords\n\n\nlicense\nstr\napache2\nLicense for the package\n\n\ncopyright\nstr\nNone\nCopyright for the package, defaults to ‘current_year onwards, author’\n\n\nstatus\nstr\n3\nDevelopment status PyPI classifier\n\n\nmin_python\nstr\n3.7\nMinimum Python version PyPI classifier\n\n\naudience\nstr\nDevelopers\nIntended audience PyPI classifier\n\n\nlanguage\nstr\nEnglish\nLanguage PyPI classifier\n\n\nrecursive\nbool_arg\nTrue\nInclude subfolders in notebook globs?\n\n\nblack_formatting\nbool_arg\nFalse\nFormat libraries with black?\n\n\nreadme_nb\nstr\nindex.ipynb\nNotebook to export as repo readme\n\n\ntitle\nstr\n%(lib_name)s\nQuarto website title\n\n\nallowed_metadata_keys\nstr\n\nPreserve the list of keys in the main notebook metadata\n\n\nallowed_cell_metadata_keys\nstr\n\nPreserve the list of keys in cell level metadata\n\n\njupyter_hooks\nbool_arg\nTrue\nRun Jupyter hooks?\n\n\nclean_ids\nbool_arg\nTrue\nRemove ids from plaintext reprs?\n\n\nclear_all\nbool_arg\nFalse\nRemove all cell metadata and cell outputs?\n\n\nput_version_in_init\nbool_arg\nTrue\nAdd the version to the main init.py in nbdev_export\n\n\n\n\n\nYou can customise nbdev for all repositories for your user with a ~/.config/nbdev/settings.ini file.\nIn order for Git actions to run smoothly, add requirements and dev_requirements with required packages in settings.ini.\nsee here as a reference."
  },
  {
    "objectID": "contributing/directives.html",
    "href": "contributing/directives.html",
    "title": "Directives",
    "section": "",
    "text": "Directives are special comments that are preceded by #| that control:\nnbdev augments Quarto by providing additional directives than what are available in Quarto. All Quarto directives can be used in nbdev notebooks.\nThis cheat sheet lists all nbdev directives in addition to some Quarto directives we believe are important. We recommend consulting the quarto docs to see all of the directives available to you.\nTo clarify the origin of directives we use the following emojis:"
  },
  {
    "objectID": "contributing/directives.html#cell-visibility",
    "href": "contributing/directives.html#cell-visibility",
    "title": "Directives",
    "section": "Cell Visibility",
    "text": "Cell Visibility\nThe following directives control cell visibility in rendered documentation:\n\n📓 #|hide\nHide cell input and output.\n\n\n\n\n\n\nExample\n\n\n\n\n\nThe following will result in the contents of the cell and it’s output from being hidden:\n#|hide\nprint('you will not see this')\nNote that using #|hide is equivalent to using the Quarto directive #|include: false:\n#|include: false\nprint('you will not see this')\nSee the quarto docs for more information about #|include.\n\n\n\n\n\n🔵 #|echo: &lt;true|false&gt;\nToggle the visibility of code-cell inputs.\n\n\n\n\n\n\nExample\n\n\n\n\n\n#|echo: false\nprint('you can see the output but not the code!')\nwhich results in:\nyou can see the output but not the code!\n\n\n\n\n\n🔵 #|output: &lt;true|false|asis&gt;\nSetting this to false hides the output of a cell. Setting this to asis renders the output as raw markdown.\n\n\n\n\n\n\nExample\n\n\n\n\n\nThe following cell will not display any output:\n#|output: false\n1 + 1\nThe following cell with #|output: asis will produce the output hello fastai rendered as markdown instead of a string:\n#|output: asis\nprint(\"`hello fastai`\")\n\n\n\n\n\n📓 #|hide_line\nHide a specific line of code in an input cell.\n\n\n\n\n\n\nExample\n\n\n\n\n\ndef _secret(): ...\n\nfor i in range(3):\n    _secret() #|hide_line\n    print(i)\nbecomes this:\n\ndef _secret(): ...\n\nfor i in range(3):\n    print(i)\n\n0\n1\n2\n\n\n\n\n\n\n\n📓 #|filter_stream &lt;keyword&gt; ...\nFilter lines containing specific keywords in cell outputs.\n\n\n\n\n\n\nExample\n\n\n\n\n\n#|filter_stream FutureWarning MultiIndex\nprint('\\n'.join(['A line', 'Foobar baz FutureWarning blah', \n                 'zig zagMultiIndex zoom', 'Another line.']))\nwill output this:\n\n\nA line\nAnother line.\n\n\n\n\n\n\n\n🔵 #|code-fold: &lt;show|true&gt;\nThe #|code-fold directive allows you to collapse code cells. When set to true, the element is collapsed by default, when set to show show the element is shown by default.\n\n\n\n\n\n\nExample\n\n\n\n\n\nWhen you set #|code-fold: true, the input cell is collapsed:\n\n\nCode\nprint('this is')\nprint('output')\nprint('that takes')\nprint('lots of vertical space')\n\n\nthis is\noutput\nthat takes\nlots of vertical space\n\n\nWhen you set #|code-fold: show the input cell is shown but still in a collapsible element:\n\n\nCode\nprint('this is')\nprint('output')\nprint('that takes')\nprint('lots of vertical space')\n\n\nthis is\noutput\nthat takes\nlots of vertical space"
  },
  {
    "objectID": "contributing/directives.html#generating-source-code",
    "href": "contributing/directives.html#generating-source-code",
    "title": "Directives",
    "section": "Generating Source Code",
    "text": "Generating Source Code\nThe following directives control how source code is exported from code cells.\n\n📓 #|default_exp &lt;name&gt;\nNames the module where cells with the #|export directive will be exported to by default.\n\n\n\n\n\n\nExample\n\n\n\n\n\n#| default_exp baz\n\n# In a new notebook cell:\n\n#| export\ndef my_function(): pass\nIf our package is named: bitsnbytes then we can do:\nfrom bitsnbytes.baz import my_function\nYou can define the package name by using lib_name in settings.ini.\n\n\n\n\n\n📓 #|export\nExports the items in the cell into the generated module and documentation.\n\n\n\n\n\n\nExample\n\n\n\n\n\n#|export\ndef say_hello(to:str # name of person to say hello to\n             ):\n    \"Say hello to somebody\"\n    return f'Hello {to}!'\nThe above cell will get exported to the module specified by #|default_exp. These exports are automatically included in __all__ for the module. To learn how export without inclusion in __all__, see the #|exporti directive.\nFurthermore, the documentation for this function will automatically be rendered like this:\n\n\nsay_hello\n\n say_hello (to:str)\n\nSay hello to somebody\n\n\n\n\nType\nDetails\n\n\n\n\nto\nstr\nname of person to say hello to\n\n\n\nThe docs are generated from this export using show_doc. See these docs for a detailed discussion of show_doc.\n\n\n\n\n\n\n📓 #|exporti\nAn internal export. Not included in __all__ or the docs. Useful for a function that is called by other functions in this module but is not part of the public API.\nEquivalently, you can prefix your function or method with _ e.g. def _private(): pass.\n\n\n📓 #|exports\nA source export. Like #|export but in addition to showing docs via showdoc.show_doc, it also shows the source code.\n\n\n\n\n\n\nExample\n\n\n\n\n\n#|exports\ndef say_hello(to):\n    \"Say hello to somebody\"\n    return f'Hello {to}!'\nthis will produce the following output:\n\ndef say_hello(to):\n    \"Say hello to somebody\"\n    return f'Hello {to}!'\n\n\n\nsay_hello\n\n say_hello (to)\n\nSay hello to somebody"
  },
  {
    "objectID": "contributing/directives.html#cell-execution",
    "href": "contributing/directives.html#cell-execution",
    "title": "Directives",
    "section": "Cell Execution",
    "text": "Cell Execution\nThe following directives allow you to control how cells are executed during docs rendering and testing.\n\n📓 #|exec_doc\nEnsures that a cell is executed each time before generating docs. When a cell does not have this annotation, it is run according to the default rules described here.\n\n\n\n\n\n\nExample\n\n\n\n\n\n\ndatetime.datetime.now()\n\ndatetime.datetime(2022, 8, 18, 9, 1, 43, 907609)\n\n\nHowever with the annotation:\n#|exec_doc\ndatetime.datetime.now()\nwe can see that the time has been updated:\n\ndatetime.datetime.now()\n\ndatetime.datetime(2023, 8, 9, 14, 2, 52, 630669)\n\n\n\n\n\n\n\n🔵 #|eval: &lt;true|false&gt;\nWhen set to false, the cell is ignored during testing.\n\n\n\n\n\n\nExample\n\n\n\n\n\n#|eval: false\nraise Exception(\"I'm not raised because I'm not run\")\n\n\n\n\n\nCell execution when there is no directive\nWhen a cell has no directives, cells are run by nbdev according to the behavior described here."
  },
  {
    "objectID": "contributing/config.html",
    "href": "contributing/config.html",
    "title": "Configuration",
    "section": "",
    "text": "All of nbdev’s configuration is done through a file called settings.ini which lives in the root of your repo. It’s in ConfigParser format. For example, here’s the first few lines of nbdev’s settings.ini file\n\n\n[DEFAULT]\nlib_name = nbdev\ndescription = Create delightful software with Jupyter Notebooks\ncopyright = 2020 onwards, Jeremy Howard\nkeywords = nbdev fastai jupyter notebook export\nuser = fastai\nauthor = Jeremy Howard and Hamel Husain\nauthor_email = j@fast.ai\nbranch = master\nmin_python = 3.7\n\n\nYou can create this file with nbdev_create_config (in which case you pass the settings manually), or with nbdev_new (which sets it up automatically for you from your repo settings). Here are all of nbdev’s settings (excluding the path and cfg_name parameters which decide where the config file is saved):\n\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nrepo\nstr\nNone\nRepo name\n\n\nbranch\nstr\nNone\nRepo default branch\n\n\nuser\nstr\nNone\nRepo username\n\n\nauthor\nstr\nNone\nPackage author’s name\n\n\nauthor_email\nstr\nNone\nPackage author’s email address\n\n\ndescription\nstr\nNone\nShort summary of the package\n\n\npath\nstr\n.\nPath to create config file\n\n\ncfg_name\nstr\nsettings.ini\nName of config file to create\n\n\nlib_name\nstr\n%(repo)s\nPackage name\n\n\ngit_url\nstr\nhttps://github.com/%(user)s/%(repo)s\nRepo URL\n\n\ncustom_sidebar\nbool_arg\nFalse\nUse a custom sidebar.yml?\n\n\nnbs_path\nPath\nnbs\nPath to notebooks\n\n\nlib_path\nPath\nNone\nPath to package root (default: repo with - replaced by _)\n\n\ndoc_path\nPath\n_docs\nPath to rendered docs\n\n\ntst_flags\nstr\nnotest\nTest flags\n\n\nversion\nstr\n0.0.1\nVersion of this release\n\n\ndoc_host\nstr\nhttps://%(user)s.github.io\nHostname for docs\n\n\ndoc_baseurl\nstr\n/%(repo)s\nBase URL for docs\n\n\nkeywords\nstr\nnbdev jupyter notebook python\nPackage keywords\n\n\nlicense\nstr\napache2\nLicense for the package\n\n\ncopyright\nstr\nNone\nCopyright for the package, defaults to ‘current_year onwards, author’\n\n\nstatus\nstr\n3\nDevelopment status PyPI classifier\n\n\nmin_python\nstr\n3.7\nMinimum Python version PyPI classifier\n\n\naudience\nstr\nDevelopers\nIntended audience PyPI classifier\n\n\nlanguage\nstr\nEnglish\nLanguage PyPI classifier\n\n\nrecursive\nbool_arg\nTrue\nInclude subfolders in notebook globs?\n\n\nblack_formatting\nbool_arg\nFalse\nFormat libraries with black?\n\n\nreadme_nb\nstr\nindex.ipynb\nNotebook to export as repo readme\n\n\ntitle\nstr\n%(lib_name)s\nQuarto website title\n\n\nallowed_metadata_keys\nstr\n\nPreserve the list of keys in the main notebook metadata\n\n\nallowed_cell_metadata_keys\nstr\n\nPreserve the list of keys in cell level metadata\n\n\njupyter_hooks\nbool_arg\nTrue\nRun Jupyter hooks?\n\n\nclean_ids\nbool_arg\nTrue\nRemove ids from plaintext reprs?\n\n\nclear_all\nbool_arg\nFalse\nRemove all cell metadata and cell outputs?\n\n\nput_version_in_init\nbool_arg\nTrue\nAdd the version to the main init.py in nbdev_export\n\n\n\n\n\nYou can customise nbdev for all repositories for your user with a ~/.config/nbdev/settings.ini file.\nIn order for Git actions to run smoothly, add requirements and dev_requirements with required packages in settings.ini.\nsee here as a reference."
  },
  {
    "objectID": "contributing/index.html",
    "href": "contributing/index.html",
    "title": "How to contribute & Document",
    "section": "",
    "text": "These explanations provide background information on how nbdev is designed and how it works. They are designed to help people who want to more deeply understand the nbdev system.\n\n\n\n\n\n\n\n\n\n\nTitle\n\n\nDescription\n\n\n\n\n\n\nDocumentation Walkthrough\n\n\nA step-by-step guide to using nbdev\n\n\n\n\nDirectives\n\n\nA cheat sheet of directives available in nbdev.\n\n\n\n\nDocs Website\n\n\nHow nbdev renders a documentation website for your project.\n\n\n\n\nConfiguration\n\n\nThe nbdev configuration file\n\n\n\n\nWhy nbdev\n\n\nWhy we develop software with nbdev\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "api/config.html",
    "href": "api/config.html",
    "title": "config",
    "section": "",
    "text": "nbdev is heavily customizeable, thanks to the configuration system defined in this module. There are 2 ways to interact with nbdev’s config:\n\nIn the terminal: nbdev_create_config creates a config file (if you’re starting a new project use nbdev_new instead)\nIn your library: get_config returns a fastcore.foundation.Config object.\n\nRead on for more about how these work.\nd### Reading a config file -\nPaths are relative to the project:\n\n# test_eq(cfg.doc_path, p/'_docs')\n# test_eq(cfg.lib_path, p/'nbdev')\n# test_eq(cfg.nbs_path, p/'nbs')\n\nIt automatically returns defaults for keys not specified in the config file. Here we create an empty config file and access lib_path and copyright even though they weren’t explicitly defined:"
  },
  {
    "objectID": "api/config.html#configuring-nbdev",
    "href": "api/config.html#configuring-nbdev",
    "title": "config",
    "section": "",
    "text": "nbdev is heavily customizeable, thanks to the configuration system defined in this module. There are 2 ways to interact with nbdev’s config:\n\nIn the terminal: nbdev_create_config creates a config file (if you’re starting a new project use nbdev_new instead)\nIn your library: get_config returns a fastcore.foundation.Config object.\n\nRead on for more about how these work.\nd### Reading a config file -\nPaths are relative to the project:\n\n# test_eq(cfg.doc_path, p/'_docs')\n# test_eq(cfg.lib_path, p/'nbdev')\n# test_eq(cfg.nbs_path, p/'nbs')\n\nIt automatically returns defaults for keys not specified in the config file. Here we create an empty config file and access lib_path and copyright even though they weren’t explicitly defined:"
  },
  {
    "objectID": "api/process.html",
    "href": "api/process.html",
    "title": "process",
    "section": "",
    "text": "These functions let us find and modify the definitions of variables in Python modules."
  },
  {
    "objectID": "api/process.html#helpers",
    "href": "api/process.html#helpers",
    "title": "process",
    "section": "",
    "text": "These functions let us find and modify the definitions of variables in Python modules."
  },
  {
    "objectID": "api/core.html",
    "href": "api/core.html",
    "title": "core",
    "section": "",
    "text": "class Card:\n    \"A playing card\"\n\n    def __init__(self,\n                 suit: int,  # An index into `suits`\n                 rank: int):  # An index into `ranks`\n        self.suit, self.rank = suit, rank\n    # def __str__(self): return f\"{ranks[self.rank]}{suits[self.suit]}\"\n    # __repr__ = __str__\n\n\n@patch\ndef __eq__(self: Card # \n           , a: Card) -&gt; bool: # Card to compare to\n    \"returns True if equal\"\n    return (self.suit, self.rank) == (a.suit, a.rank)\n\n\n@patch\ndef __lt__(self: Card, a: Card): return (self.suit, self.rank) &lt; (a.suit, a.rank)\n\n\n@patch\ndef __gt__(self: Card, a: Card): return (self.suit, self.rank) &gt; (a.suit, a.rank)\n\n# @patch\n# def eq(self: Card, a: Card):\n#     return (self.suit, self.rank) == (a.suit, a.rank)\n\n\n# show_doc(Card.__eq__ )\n\n\n\nCard.__eq__\n\n Card.__eq__ (a:__main__.Card)\n\nreturns True if equal\n\n\n\n\nType\nDetails\n\n\n\n\na\nCard\n\n\n\nReturns\nbool\nCard to compare to\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote that there are five types of callouts, including: note, warning, important, tip, and caution.\n\n\n\n\n\n\n\n\nJupyter\n\n\n\n\n\n\n\nVscode\n\n\n\n\n\n\n\nGit\n\n\n\n\n\n\n\nsay_gday\n\n say_gday (greeting:str=\"G'day\", strine:bool=True, dropbears:bool=False)\n\nSays g’day, the classic Aussie greeting\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ngreeting\nstr\nG’day\nGreeting to use\n\n\nstrine\nbool\nTrue\nUse incomprehensible Aussie accent?\n\n\ndropbears\nbool\nFalse\nAlso warn about drop-bears?\n\n\n\n/home/jn/PycharmProjects/UAV/venv/lib/python3.10/site-packages/fastcore/docscrape.py:225: UserWarning: Unknown section See Also\n  else: warn(msg)\n/home/jn/PycharmProjects/UAV/venv/lib/python3.10/site-packages/fastcore/docscrape.py:225: UserWarning: Unknown section Notes\n  else: warn(msg)\n/home/jn/PycharmProjects/UAV/venv/lib/python3.10/site-packages/fastcore/docscrape.py:225: UserWarning: Unknown section Examples\n  else: warn(msg)\n\n\n\nall\n\n all (a, axis=None, out=None, keepdims=&lt;no value&gt;, where=&lt;no value&gt;)\n\nTest whether all array elements along a given axis evaluate to True.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\na\narray_like\n\nInput array or object that can be converted to an array.\n\n\naxis\nNoneType\nNone\nAxis or axes along which a logical AND reduction is performed.The default (axis=None) is to perform a logical AND over allthe dimensions of the input array. axis may be negative, inwhich case it counts from the last to the first axis... versionadded:: 1.7.0If this is a tuple of ints, a reduction is performed on multipleaxes, instead of a single axis or all the axes as before.\n\n\nout\nNoneType\nNone\nAlternate output array in which to place the result.It must have the same shape as the expected output and itstype is preserved (e.g., if dtype(out) is float, the resultwill consist of 0.0’s and 1.0’s). See :ref:ufuncs-output-type for moredetails.\n\n\nkeepdims\n_NoValueType\n\nIf this is set to True, the axes which are reduced are leftin the result as dimensions with size one. With this option,the result will broadcast correctly against the input array.If the default value is passed, then keepdims will not bepassed through to the all method of sub-classes ofndarray, however any non-default value will be. If thesub-class’ method does not implement keepdims anyexceptions will be raised.\n\n\nwhere\n_NoValueType\n\nElements to include in checking for all True values.See ~numpy.ufunc.reduce for details... versionadded:: 1.20.0\n\n\nReturns\nndarray, bool\n\nA new boolean or array is returned unless out is specified,in which case a reference to out is returned.\n\n\n\n\n\nMarkdown for Jupyter notebooks cheatsheet\ncheatsheet\n\n\nMake a requirements.txt file\nIt is used to scan your imports and build a Python requirements file for you. It is a good idea to run this command after you have finished your notebook and before you commit your changes to source control.\npip install pipreqs\npipreqs --force --mode gt ."
  },
  {
    "objectID": "api/index.html",
    "href": "api/index.html",
    "title": "API",
    "section": "",
    "text": "This section contains API details for each of projects python submodules. This reference documentation is mainly useful for people looking to customise or build on top of the API, or wanting detailed information about how the API works.\n\n\n\n\n\n\n\n\n\n\nTitle\n\n\nDescription\n\n\n\n\n\n\nGstreamer Valve\n\n\nGstreamer video capture with on/off valve\n\n\n\n\nUtils.Display\n\n\nFill in a module description here\n\n\n\n\nconfig\n\n\nConfiguring nbdev and bootstrapping notebook export\n\n\n\n\ncore\n\n\nFill in a module description here\n\n\n\n\nmaker\n\n\nCreate one or more modules from selected notebook cells\n\n\n\n\nprocess\n\n\nCreate bla bla\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/posts/2022-11-07-spaces/index.html",
    "href": "blog/posts/2022-11-07-spaces/index.html",
    "title": "Create A 🤗 Space From A Notebook",
    "section": "",
    "text": "Image created with Stable Diffusion from this space\nHugging Face Spaces provides an easy ways to deploy a web app with python. Gradio is one of my favorite tools for building these web apps. For example, the cover-image for this blog post was generated with a Gradio App!1 Gradio also allows you to prototype your web apps in notebooks which allows you to iterate fast. Unfortunately, Hugging Face Spaces requires you to package your web application code as a python script named app.py.\nHowever, thanks to nbdev, you can deploy a Gradio app to Spaces from a notebook without having to refactor your code into a script! When you finish this tutorial, you will have an app that looks like this:\nThe above app allows you to lookup the size of any Hugging Face Dataset, using the Hugging Face Datasets Server API.\nAuthoring your spaces in notebooks offers a number of benefits such as the ability to:\n… All from the same environment!"
  },
  {
    "objectID": "blog/posts/2022-11-07-spaces/index.html#create-a-gradio-enabled-space-on-hugging-face",
    "href": "blog/posts/2022-11-07-spaces/index.html#create-a-gradio-enabled-space-on-hugging-face",
    "title": "Create A 🤗 Space From A Notebook",
    "section": "1. Create a Gradio-enabled Space on Hugging Face",
    "text": "1. Create a Gradio-enabled Space on Hugging Face\nThe first step is to create a space and select the appropriate sdk (which is Gradio in this example), according to these instructions:\n\n\n\ncreate a Hugging Face Space\n\n\nAfter you are done creating the space, clone the repo locally. In this example, I ran the command git clone https://huggingface.co/spaces/hamel/hfspace_demo."
  },
  {
    "objectID": "blog/posts/2022-11-07-spaces/index.html#create-a-notebook",
    "href": "blog/posts/2022-11-07-spaces/index.html#create-a-notebook",
    "title": "Create A 🤗 Space From A Notebook",
    "section": "2. Create A Notebook",
    "text": "2. Create A Notebook\nBefore getting started you will want to install the dependencies for this tutorial:\n!pip install git+https://github.com/fastai/nbdev.git gradio fastcore\nCreate a notebook called app.ipynb in the root of your newly cloned repo. Alternatively, download the notebook and follow along.\n\n\n\n\n\n\nDownload the notebook and follow along\n\n\n\nThis blog post is a verbose version of the “notebook” you can use to create a Gradio app. However, it can be useful to see just the code without any of the prose. A concise version of this notebook is here. I recommend taking a look at this notebook during or after you read this blog post."
  },
  {
    "objectID": "blog/posts/2022-11-07-spaces/index.html#make-an-app-with-gradio",
    "href": "blog/posts/2022-11-07-spaces/index.html#make-an-app-with-gradio",
    "title": "Create A 🤗 Space From A Notebook",
    "section": "3. Make an app with Gradio",
    "text": "3. Make an app with Gradio\nBelow, I will create a gradio app in a notebook and show you how to deploy it to Hugging Face Spaces.\nFirst, lets import the libraries we need, which in this case are gradio and fastcore:\n#|export\nimport gradio as gr\nfrom fastcore.net import urljson, HTTPError\nNext, write the functions your gradio app will use. Because of nbdev, you can prototype and package your code all in one place. The special comment #|export marks which cells will be sent to a python script (more on this later). Note that there are only three cells in this notebook with the #|export directive.\n#|export\ndef size(repo:str):\n    \"Returns the size in GB of a HuggingFace Dataset.\"\n    url = f'https://huggingface.co/api/datasets/{repo}'\n    try: resp = urljson(f'{url}/treesize/main')\n    except HTTPError: return f'Did not find repo: {url}'\n    gb = resp['size'] / 1e9\n    return f'{gb:.2f} GB'\nsize takes as an input a Hugging Face Dataset repo and returns the total size in GB of the data.\nFor example, I can check the size of tglcourse/CelebA-faces-cropped-128 like so:\nsize(\"tglcourse/CelebA-faces-cropped-128\")\n\n'5.49 GB'\n\nYou can construct a simple UI with the gradio.interface and then call the launch method of that interface to display a preview in a notebook. This is a great way to test your app to see if it works:\n#|export\niface = gr.Interface(fn=size, inputs=gr.Text(value=\"tglcourse/CelebA-faces-cropped-128\"), outputs=\"text\")\niface.launch(height=450, width=500)\n\nRunning on local URL:  http://127.0.0.1:7861\n\nTo create a public link, set `share=True` in `launch()`.\n\n\nNote how running the launch() method in a notebook runs a webserver in the background. Below, I call the close() method to close the webserver.\n# this is only necessary in a notebook\niface.close()\n\nClosing server running on port: 7861"
  },
  {
    "objectID": "blog/posts/2022-11-07-spaces/index.html#convert-this-notebook-into-a-gradio-app",
    "href": "blog/posts/2022-11-07-spaces/index.html#convert-this-notebook-into-a-gradio-app",
    "title": "Create A 🤗 Space From A Notebook",
    "section": "4. Convert This Notebook Into A Gradio App",
    "text": "4. Convert This Notebook Into A Gradio App\nIn order to host this code on Hugging Face Spaces, you will export parts of this notebook to a script named app.py. As a reminder, this is what the special #|export comment that you have seen in cells above do! You can export code from this notebook like so:\nfrom nbdev.export import nb_export\nnb_export('app.ipynb', lib_path='.', name='app')\n\nUnderstanding what is generated\nNotice how the contents of app.py only contain the exported cells from this notebook:\n!cat app.py\n\n# AUTOGENERATED! DO NOT EDIT! File to edit: app.ipynb.\n\n# %% auto 0\n__all__ = ['iface', 'size']\n\n# %% app.ipynb 6\nimport gradio as gr\nfrom fastcore.net import urljson, HTTPError\n\n# %% app.ipynb 8\ndef size(repo:str):\n    \"Returns the size in GB of a HuggingFace Dataset.\"\n    url = f'https://huggingface.co/api/datasets/{repo}'\n    try: resp = urljson(f'{url}/treesize/main')\n    except HTTPError: return f'Did not find repo: {url}'\n    gb = resp['size'] / 1e9\n    return f'{gb:.2f} GB'\n\n# %% app.ipynb 12\niface = gr.Interface(fn=size, inputs=gr.Text(value=\"tglcourse/CelebA-faces-cropped-128\"), outputs=\"text\")\niface.launch(height=450, width=500)\n\n\n\nFill out requirements.txt\nYou must supply a requirements.txt file so the Gradio app knows how to build your dependencies. In this example, the only dependency other than Gradio is fastcore. You don’t need to specify Gradio itself as a dependency in requirements.txt, so our requirements.txt file has only one dependency:\n%%writefile requirements.txt\nfastcore\nWriting requirements.txt\nNote: you may want to add operating system dependencies in addition to python dependencies. You can do this via a packages.txt file as documented here."
  },
  {
    "objectID": "blog/posts/2022-11-07-spaces/index.html#launch-your-gradio-app",
    "href": "blog/posts/2022-11-07-spaces/index.html#launch-your-gradio-app",
    "title": "Create A 🤗 Space From A Notebook",
    "section": "5. Launch Your Gradio App",
    "text": "5. Launch Your Gradio App\nTo launch your gradio app, you need to commit the changes to the Hugging Face repo:\ngit add -A; git commit -m \"Add application files\"; git push"
  },
  {
    "objectID": "blog/posts/2022-11-07-spaces/index.html#footnotes",
    "href": "blog/posts/2022-11-07-spaces/index.html#footnotes",
    "title": "Create A 🤗 Space From A Notebook",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe prompt that generated the cover image is: “A data scientist at a computer in a futuristic city with a view of the planet Jupyter in the night sky, trending on artstation, high detail, science-fiction”↩︎"
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "nbdev Blog",
    "section": "",
    "text": "Create A 🤗 Space From A Notebook\n\n\n\n\n\nA demo of using nbdev with Hugging Face Spaces & Gradio.\n\n\n\n\n\n\nNov 7, 2022\n\n\nHamel Husain\n\n\n\n\n\n\n  \n\n\n\n\nThe Jupyter+git problem is now solved\n\n\n\n\n\nPreviously, using git with Jupyter could create conflicts and break notebooks. With nbdev2, the problem has been totally solved.\n\n\n\n\n\n\nAug 25, 2022\n\n\nJeremy Howard\n\n\n\n\n\n\n  \n\n\n\n\nnbdev+Quarto: A new secret weapon for productivity\n\n\n\n\n\nOur favorite tool for software engineering productivity–nbdev, now re-written with Quarto\n\n\n\n\n\n\nJul 28, 2022\n\n\nHamel Husain, Jeremy Howard\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "getting_started.html",
    "href": "getting_started.html",
    "title": "Getting Started",
    "section": "",
    "text": "NB: This is nbdev v2, a major upgrade of nbdev. Whilst the differences to nbdev1 aren’t huge, it does require some changes. The old version docs are at nbdev1.fast.ai. You can use version-pinning in settings.ini (i.e 'nbdev&lt;2') to stop nbdev from upgrading. To upgrade, follow the migration tutorial.\nnbdev is a notebook-driven development platform. Simply write notebooks with lightweight markup and get high-quality documentation, tests, continuous integration, and packaging for free!\nnbdev makes debugging and refactoring your code much easier than in traditional programming environments since you always have live objects at your fingertips. nbdev also promotes software engineering best practices because tests and documentation are first class."
  },
  {
    "objectID": "getting_started.html#install",
    "href": "getting_started.html#install",
    "title": "Getting Started",
    "section": "Install",
    "text": "Install\nnbdev works on macOS, Linux, and most Unix-style operating systems. It works on Windows under WSL, but not under cmd or Powershell.\nYou can install nbdev with pip:\npip install nbdev\n… or with conda (or mamba):\nconda install -c fastai nbdev\nNote that nbdev must be installed into the same Python environment that you use for both Jupyter and your project."
  },
  {
    "objectID": "getting_started.html#how-to-use-nbdev",
    "href": "getting_started.html#how-to-use-nbdev",
    "title": "Getting Started",
    "section": "How to use nbdev",
    "text": "How to use nbdev\nThe best way to learn how to use nbdev is to complete either the written walkthrough or video walkthrough:\n\n\nAlternatively, there’s a shortened version of the video walkthrough with coding sections sped up using the unsilence Python library – it’s 27 minutes faster, but a bit harder to follow.\nYou can also run nbdev_help from the terminal to see the full list of available commands:\n\n!nbdev_help\n\nnbdev_bump_version              Increment version in settings.ini by one\nnbdev_changelog                 Create a CHANGELOG.md file from closed and labeled GitHub issues\nnbdev_clean                     Clean all notebooks in `fname` to avoid merge conflicts\nnbdev_conda                     Create a `meta.yaml` file ready to be built into a package, and optionally build and upload it\nnbdev_create_config             Create a config file.\nnbdev_deploy                    Deploy docs to GitHub Pages\nnbdev_docs                      Create Quarto docs and README.md\nnbdev_export                    Export notebooks in `path` to Python modules\nnbdev_filter                    A notebook filter for Quarto\nnbdev_fix                       Create working notebook from conflicted notebook `nbname`\nnbdev_help                      Show help for all console scripts\nnbdev_install                   Install Quarto and the current library\nnbdev_install_hooks             Install Jupyter and git hooks to automatically clean, trust, and fix merge conflicts in notebooks\nnbdev_install_quarto            Install latest Quarto on macOS or Linux, prints instructions for Windows\nnbdev_merge                     Git merge driver for notebooks\nnbdev_migrate                   Convert all directives and callouts in `fname` from v1 to v2\nnbdev_new                       Create an nbdev project.\nnbdev_prepare                   Export, test, and clean notebooks, and render README if needed\nnbdev_preview                   Preview docs locally\nnbdev_proc_nbs                  Process notebooks in `path` for docs rendering\nnbdev_pypi                      Create and upload Python package to PyPI\nnbdev_readme                    None\nnbdev_release_both              Release both conda and PyPI packages\nnbdev_release_gh                Calls `nbdev_changelog`, lets you edit the result, then pushes to git and calls `nbdev_release_git`\nnbdev_release_git               Tag and create a release in GitHub for the current version\nnbdev_sidebar                   Create sidebar.yml\nnbdev_test                      Test in parallel notebooks matching `path`, passing along `flags`\nnbdev_trust                     Trust notebooks matching `fname`\nnbdev_update                    Propagate change in modules matching `fname` to notebooks that created them"
  },
  {
    "objectID": "getting_started.html#faq",
    "href": "getting_started.html#faq",
    "title": "Getting Started",
    "section": "FAQ",
    "text": "FAQ\n\nQ: What is the warning “Found a cell containing mix of imports and computations. Please use separate cells”?\nA: You should not have cells that are not exported, and contain a mix of import statements along with other code. For instance, don’t do this in a single cell:\nimport some_module\nsome_module.something()\nInstead, split this into two cells, one which does import some_module, and the other which does some_module.something().\nThe reason for this is that when we create your documentation website, we ensure that all of the signatures for functions you document are up to date, by running the imports, exported cells, and show_doc functions in your notebooks. When you mix imports with other code, that other code will be run too, which can cause errors (or at least slowdowns) when creating your website.\n\n\nQ: Why is nbdev asking for root access? How do I install Quarto without root access?\nA: When you setup your first project, nbdev will attempt to automatically download and install Quarto for you. This is the program that we use to create your documentation website.\nQuarto’s standard installation process requires root access, and nbdev will therefore ask for your root password during installation. For most people, this will work fine and everything will be handled automatically – if so, you can skip over the rest of this section, which talks about installing without root access.\nIf you need to install Quarto without root access on Linux, first cd to wherever you want to store it, then download Quarto, and type:\ndpkg -x quarto*.deb .\nmv opt/quarto ./\nrmdir opt\nmkdir -p ~/.local/bin\nln -s \"$(pwd)\"/quarto/bin/quarto ~/.local/bin\nTo use this non-root version of Quarto, you’ll need ~/.local/bin in your PATH environment variable. (Alternatively, change the ln -s step to place the symlink somewhere else in your path.)\n\n\nQ: Someone told me not to use notebooks for “serious” software development!\nA: Watch this video. Don’t worry, we still get this too, despite having used nbdev for a wide range of “very serious” software projects over the last three years, including deep learning libraries, API clients, Python language extensions, terminal user interfaces, and more!"
  },
  {
    "objectID": "getting_started.html#contributing",
    "href": "getting_started.html#contributing",
    "title": "Getting Started",
    "section": "Contributing",
    "text": "Contributing\nIf you want to contribute to nbdev, be sure to review the contributions guidelines. This project adheres to fastai’s code of conduct. By participating, you are expected to uphold this code. In general, we strive to abide by generally accepted best practices in open-source software development.\nMake sure you have nbdev’s git hooks installed by running nbdev_install_hooks in the cloned repository."
  },
  {
    "objectID": "getting_started.html#copyright",
    "href": "getting_started.html#copyright",
    "title": "Getting Started",
    "section": "Copyright",
    "text": "Copyright\nCopyright © 2019 onward fast.ai, Inc. Licensed under the Apache License, Version 2.0 (the “License”); you may not use this project’s files except in compliance with the License. A copy of the License is provided in the LICENSE file in this repository."
  },
  {
    "objectID": "blog/posts/2022-08-25-jupyter-git/index.html",
    "href": "blog/posts/2022-08-25-jupyter-git/index.html",
    "title": "The Jupyter+git problem is now solved",
    "section": "",
    "text": "Originally posted on the fast.ai blog"
  },
  {
    "objectID": "blog/posts/2022-08-25-jupyter-git/index.html#the-jupytergit-problem",
    "href": "blog/posts/2022-08-25-jupyter-git/index.html#the-jupytergit-problem",
    "title": "The Jupyter+git problem is now solved",
    "section": "The Jupyter+git problem",
    "text": "The Jupyter+git problem\nJupyter notebooks are a powerful tool for scientists, engineers, technical writers, students, teachers, and more. They provide an ideal notebook environment for interactively exploring data and code, writing programs, and documenting the results as dashboards, books, or blogs.\nBut when collaborating with others, this ideal environment goes up in smoke. That’s because tools such as git, which are the most popular approaches for asynchronous collaboration, makes notebooks unusable. Literally. Here’s what it looks like if you and a colleague both modify a notebook cell (including, in many cases, simply executing a cell withuout changing it), and then try to open that notebook later:\n\n\n\nWhat merge conflicts normally do to Jupyter Notebooks\n\n\nThe reason for this stems from a fundamental incompatibility between the format Jupyter notebooks use (JSON) and the format that git conflict markers assume by default (plain lines of text). This is what it looks like when git adds its conflict markers to a notebook:\n\n   \"source\": [\n&lt;&lt;&lt;&lt;&lt;&lt; HEAD\n    \"z=3\\n\",\n======\n    \"z=2\\n\",\n&gt;&gt;&gt;&gt;&gt;&gt; a7ec1b0bfb8e23b05fd0a2e6cafcb41cd0fb1c35\n    \"z\"\n   ]\n\nThat’s not valid JSON, and therefore Jupyter can’t open it. Conflicts are particularly common in notebooks, because Jupyter changes the following every time you run a notebook:\n\nEvery cell includes a number indicating what order it was run in. If you and a colleague run the cells in different orders, you’ll have a conflict in every single cell! This would take a very long time to fix manually\nFor every figure, such as a plot, Jupyter includes not only the image itself in the notebook, but also a plain text description that includes the id (like a memory address) of the object, such as &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fbc113dbe90&gt;. This changes every time you execute a notebook, and therefore will create a conflict every time two people execute this cell\nSome outputs may be non-deterministic, such as a notebook that uses random numbers, or that interacts with a service that provides different outputs over time (such as a weather service)\nJupyter adds metadata to the notebook describing the environment it was last run in, such as the name of the kernel. This often varies across installations, and therefore two people saving a notebook (even without and other changes) will often end up with a conflict in the metadata.\n\nAll these changes to notebook files also make git diffs of notebooks very verbose. This can make code reviews a challenge, and make git repos more bulky than necessary.\nThe result of these problems is that many Jupyter users feel that collaborating with notebooks is a clunky, error-prone, and frustrating experience. (We’ve even seen people on social media describe Jupyter’s notebook format as “stupid” or “terrible”, despite otherwise professing their love for the software!)\nIt turns out, however, that Jupyter and git can work together extremely well, with none of the above problems at all. All that’s needed is a bit of special software…"
  },
  {
    "objectID": "blog/posts/2022-08-25-jupyter-git/index.html#the-solution",
    "href": "blog/posts/2022-08-25-jupyter-git/index.html#the-solution",
    "title": "The Jupyter+git problem is now solved",
    "section": "The solution",
    "text": "The solution\nJupyter and git are both well-designed software systems that provide many powerful extensibility mechanisms. It turns out that we can use these to fully and automatically solve the Jupyter+git problem. We identified two categories of problems in the previous section:\n\ngit conflicts lead to broken notebooks\nUnnecessary conflicts due to metadata and outputs.\n\nIn our newly released nbdev2, an open source Jupyter-based development platform, we’ve solve each of the problems:\n\nA new merge driver for git provides “notebook-native” conflict markers, resulting in notebooks that can be opened directly in Jupyter, even when there are git conflicts\nA new save hook for Jupyter automatically removes all unnecessary metadata and non-deterministic cell output.\n\nHere’s what a conflict looks like in Jupyter with nbdev’s merge driver:\n\n\n\nAs you see, the local and remote change are each clearly displayed as separate cells in the notebook, allowing you to simply delete the version you don’t want to keep, or combine the two cells as needed.\nThe techniques used to make the merge driver work are quite fascinating – let’s dive into the details!\n\nThe nbdev2 git merge driver\nWe provide here a summary of the git merge driver – for full details and source code see the nbdev.merge docs. Amazingly enough, the entire implementation is just 58 lines of code!\nThe basic idea is to first “undo” the original git merge which created the conflict, and then “redo” it at a cell level (instead of a line level) and looking only at cell source (not outputs or metadata). The “undoing” is straightforward: just create two copies of the conflicted file (representing the local and remove versions of the file), go through each git conflict marker, and replace the conflict section with either the local or remote version of the code.\nNow that we’ve got the original local and remote notebooks, we can load the json using execnb.nbio, which will then give us an array of cells for each notebook. Now we’re up to the interesting bit – creating cell-level diffs based only on the cell source.\nThe Python standard library contains a very flexible and effective implementation of a diff algorithm in the difflib module. In particular, the SequenceMatcher class provides the fundamental building blocks for implementing your own conflict resolution system. We pass the two sets of cells (remote and local) to SequenceMatcher(...).get_matching_blocks(), and it returns a list of each section of cells that match (i.e. have no conflicts/differences). We can then go through each matching section and copy them into the final notebook, and through each non-matching section and copy in each of the remote and local cells (add cells between them to mark the conflicts).\nMaking SequenceMatcher work with notebook cells (represented in nbdev by the NbCell class) requires only adding __hash__ and __eq__ methods to NbCell. In each case, these methods are defined to look only at the actual source code, and not at any metadata or outputs. As a result, SequenceMatcher will only show differences in source code, and will ignore differences in everything else.\nWith a single line of configuration, we can ask git to call our python script, instead of its default line-based implementation, any time it is merging changes. nbdev_install_hooks sets up this configuration automatically, so after running it, git conflicts become much less common, and never result in broken notebooks.\n\n\nThe nbdev2 Jupyter save hook\nSolving git merges locally is extremely helpful, but we need to solve them remotely as well. For instance, if a contributor submits a pull request (PR), and then someone else commits to the same notebook before the PR is merged, the PR might now have a conflict like this:\n\n   \"outputs\": [\n    {\n&lt;&lt;&lt;&lt;&lt;&lt; HEAD\n     \"execution_count\": 7,\n======\n     \"execution_count\": 5,\n&gt;&gt;&gt;&gt;&gt;&gt; a7ec1b0bfb8e23b05fd0a2e6cafcb41cd0fb1c35\n     \"metadata\": {},\n\nThis conflict shows that the two contributors have run cells in different orders (or perhaps one added a couple of cells above in the notebook), so their commits have conflicting execution counts. GitHub will refuse to allow this PR to be merged until this conflict is fixed.\nBut of course we don’t really care about the conflict at all – it doesn’t matter what, if any, execution count is stored in the notebook. So we’d really prefer to ignore this difference entirely!\nThankfully, Jupyter provides a “pre-save” hook which allows code to be run every time a notebook is saved. nbdev uses this to set up a hook which removes all unnecessary metadata (including execution_count) on saving. That means there’s no pointless conflicts like the one above, because no commits will have this information stored in the first place."
  },
  {
    "objectID": "blog/posts/2022-08-25-jupyter-git/index.html#background",
    "href": "blog/posts/2022-08-25-jupyter-git/index.html#background",
    "title": "The Jupyter+git problem is now solved",
    "section": "Background",
    "text": "Background\nHere at fast.ai we use Jupyter for everything. All our tests, documentation, and module source code for all of our many libraries is entirely developed in notebooks (using nbdev, of course!) And we use git for all our libraries too. Some of our repositories have many hundreds of contributors. Therefore solving the Jupyter+git problem has been critical for us. The solution presented here is the result of years of work by many people.\nOur first approach, developed by Stas Bekman and me, was to use git “smudge” and “clean” filters that automatically rewrote all notebook json to remove unneeded metadata when committing. This helped a bit, but git quite often ended up in an odd state where it was impossible to merge.\nIn nbdev v1 Sylvain Gugger created an amazing tool called nbdev_fix_merge which used very clever custom logic to manually fix merge conflicts in notebooks, to ensure that they could opened in Jupyter. For nbdev v2 I did a from-scratch rewrite of every part of the library, and I realised that we could replace the custom logic with the SequenceMatcher approach described above.\nNone of these steps fully resolved the Jupyter+git problem, since we were getting frequent merge errors caused by the smudge/clean git filters, and conflicts required manually running nbdev_fix_merge. Wasim Lorgat realised that we could resolve the smudge/clean issue by moving that logic into an nbdev save hook, and avoid the manual fix step by moving that logic into a git merge driver. This resolved the final remaining issues! (I was actually quite stunned that Wasim went from our first discussion of the outstanding problems, to figuring out how to solve all of them, in the space of about two days…)"
  },
  {
    "objectID": "blog/posts/2022-08-25-jupyter-git/index.html#the-result",
    "href": "blog/posts/2022-08-25-jupyter-git/index.html#the-result",
    "title": "The Jupyter+git problem is now solved",
    "section": "The result",
    "text": "The result\nThe new tools in nbdev2, which we’ve been using internally for the last few months, have been transformational to our workflow. The Jupyter+git problem has been totally solved. I’ve seen no unnecessary conflicts, cell-level merges have worked like magic, and on the few occassions where I’ve changed the source in the same cell as a collaborator, fixing the conflict in Jupyter has been straightforward and convenient."
  },
  {
    "objectID": "blog/posts/2022-08-25-jupyter-git/index.html#postscript-other-jupytergit-tools",
    "href": "blog/posts/2022-08-25-jupyter-git/index.html#postscript-other-jupytergit-tools",
    "title": "The Jupyter+git problem is now solved",
    "section": "Postscript: other Jupyter+git tools",
    "text": "Postscript: other Jupyter+git tools\n\nReviewNB\nThere is one other tool which we’ve found very helpful in using Jupyter with git, which is ReviewNB. ReviewNB solves the problem of doing pull requests with notebooks. GitHub’s code review GUI only works well for line-based file formats, such as plain python scripts. This works fine with the Python modules that nbdev exports, and I often do reviews directly on the Python files, instead of the source notebooks.\nHowever, much of the time I’d rather do reviews on the source notebooks, because:\n\nI want to review the documentation and tests, not just the implementation\nI want to see the changes to cell outputs, such as charts and tables, not just the code.\n\nFor this purpose, ReviewNB is perfect. Just like nbdev makes git merges and commits Jupyter-friendly, ReviewNB makes code reviews Jupyter-friendly. A picture is worth a thousand words, so rather than trying to explain, I’ll just show this picture from the ReviewNB website of what PRs look like in their interface:\n\n\n\nAn alternative solution: Jupytext\nAnother potential solution to the Jupyter+git problem might be to use Jupytext. Jupytext saves notebooks in a line-based format, instead of in JSON. This means that all the usual git machinery, such as merges and PRs, works fine. Jupytext can even use Quarto’s format, qmd, as a format for saving notebooks, which then can be used to generate a website.\nJupytext can be a bit tricky to manage when you want to save your cell outputs (which I generally want to do, since many of my notebooks take a long time to run – e.g training deep learning models.) Whilst Jupytext can save outputs in a linked ipynb file, managing this linkage gets complex, and ends up with the Jupyter+git problem all over again! If you don’t need to save outputs, then you might find Jupytext sufficient – although of course you’ll miss out on the cell-based code reviews of ReviewNB and your users won’t be able to read your notebooks properly when they’re browsing GitHub.\n\n\nnbdime\nThere’s also an interesting project called nbdime which has its own git drivers and filters. Since they’re not really compatible with nbdev (partly because they tackle some of the same problems in different ways) I haven’t used them much, so haven’t got an informed opinion about them. However I do use nbdime’s Jupyter extension sometimes, which provides a view similar to ReviewNB, but for local changes instead of PRs.\nIf you want to try to yourself, follow the directions on Git-friendly Jupyter to get started."
  },
  {
    "objectID": "blog/posts/2022-07-28-nbdev2/index.html",
    "href": "blog/posts/2022-07-28-nbdev2/index.html",
    "title": "nbdev+Quarto: A new secret weapon for productivity",
    "section": "",
    "text": "Originally posted on the fast.ai blog"
  },
  {
    "objectID": "blog/posts/2022-07-28-nbdev2/index.html#our-new-secret-weapon-for-productivity",
    "href": "blog/posts/2022-07-28-nbdev2/index.html#our-new-secret-weapon-for-productivity",
    "title": "nbdev+Quarto: A new secret weapon for productivity",
    "section": "Our new secret weapon for productivity",
    "text": "Our new secret weapon for productivity\nToday we’re excited to announce that we’ve teamed up with Quarto to give nbdev superpowers. nbdev offers Python programmers a common set of tools for using Jupyter notebooks to:\n\nWrite & distribute software packages\nTest code, and\nAuthor documentation and technical articles\n\nAlthough notebooks are already widely used for once-off exploratory work, it’s less well-known that they are perfectly capable of writing quality software. In fact, we’ve used nbdev for a wide range of software projects over the last three years, including deep learning libraries, API clients, Python language extensions, terminal user interfaces, and more. We discovered that it is not only capable of writing great software but that it has also increased our productivity by 300% or more. With nbdev, developers simply write notebooks with lightweight markup and get high-quality documentation, tests, continuous integration, and packaging for free! Nbdev has allowed us to maintain and scale many open source projects. Pull requests are often accompanied by detailed documentation and tests–contributors simply write notebooks.\nThis is why we’re excited to share nbdev v2. It’s rewritten from the ground up, with much-anticipated features including:\n\nInteroperation with non-nbdev codebases for tasks like documentation\nSupport for any static site generator\nWide variety of output mediums such as blogs, papers, slides, and websites\nA faster Jupyter kernel, which also means faster tests\nCleaner and more extensible API, which supports custom directives, custom module exporters, and more"
  },
  {
    "objectID": "blog/posts/2022-07-28-nbdev2/index.html#nbdev-in-industry",
    "href": "blog/posts/2022-07-28-nbdev2/index.html#nbdev-in-industry",
    "title": "nbdev+Quarto: A new secret weapon for productivity",
    "section": "nbdev in industry",
    "text": "nbdev in industry\nWe have piloted nbdev at several companies. We were delighted to receive the following feedback, which fits our own experience using and developing nbdev:\n\n\n\nDavid Berg, on using nbdev for internal documentation at Netflix: “Prior to using nbdev, documentation was the most cumbersome aspect of our software development process… Using nbdev allows us to spend more time creating rich prose around the many code snippets guaranteeing the whole experience is robust. nbdev has turned what was once a chore into a natural extension of the notebook-based testing we were already doing.”\n\n\n\n\n\n\n\n\n\n\n\n\n\nErik Gaasedelen, on using nbdev in production at Lyft: “I use this in production at my company. It’s an awesome tool… nbdev streamlines everything so I can write docs, tests, and code all in one place… The packaging is also really well thought out. From my point of view it is close to a Pareto improvement over traditional Python library development.”\n\n\n\n\n\n\n\n\n\n\n\n\n\nHugo Bowne-Anderson, on using nbdev for Outerbounds: “nbdev has transformed the way we write documentation. Gone are the days of worrying about broken code examples when our API changes or [due to] human errors associated with copying & pasting code into markdown files. The authoring experience of nbdev… [allows] us to write prose and live code in a unified interface, which allows more experimentation… On top of this, nbdev allows us to include unit tests in our documentation which mitigates the burden of maintaining the docs over time.”\n\n\n\n\n\n\n\n\n\n\n\n\n\nRoxanna Pourzand, on using nbdev for Transform: “We’re so excited about using nbdev. Our product is technical so our resulting documentation includes a lot of code-based examples. Before nbdev, we had no way of maintaining our code examples and ensuring that it was up-to-date for both command inputs and outputs. It was all manual. With nbdev, we now have this under control in a sustainable way. Since we’ve deployed these docs, we also had a situation where we were able to identify a bug in one of our interfaces, which we found by seeing the error that was output in the documentation.”"
  },
  {
    "objectID": "blog/posts/2022-07-28-nbdev2/index.html#whats-nbdev",
    "href": "blog/posts/2022-07-28-nbdev2/index.html#whats-nbdev",
    "title": "nbdev+Quarto: A new secret weapon for productivity",
    "section": "What’s nbdev?",
    "text": "What’s nbdev?\nNbdev embraces the dynamic nature of python and REPL-driven development in ways that traditional IDEs and software development workflows cannot. We thoroughly discussed the motivation, history, and goals of nbdev in this initial launch post three years ago. The creator of Jupyter, Fernando Pérez, told us:\n\n[Nbdev] should be celebrated and used a lot more - I have kept a tab with your original nbdev blog post open for months in Chrome because of how often I refer to it and point others to this work\n\nIn short, nbdev embraces ideas from literate programming and exploratory programming. These paradigms have been revisited in platforms like XCode Playgrounds and languages like Smalltalk, LISP, and Mathematica. With nbdev, we sought to push these paradigms even further by enabling it for one of the most popular dynamic programming languages in the world: Python.\n\n\n\nState of the Octoverse 2021, GitHub\n\n\nEven though nbdev is most widely used in scientific computing communities due to its integration with Jupyter Notebooks, we’ve found that nbdev is well suited for a much wider range of software. We have used nbdev to write deep learning libraries, API clients, python language extensions, terminal user interfaces, and more!\nHamel: When I use nbdev, my colleagues are often astounded by how quickly I can create and distribute high-quality python packages. I consider nbdev to be a superpower that allows me to create tests and documentation without any additional friction, which makes all of my projects more maintainable. I also find writing software with nbdev to be more fun and productive as I can iterate very fast on ideas relative to more traditional software engineering workflows. Lastly, with nbdev I can also use traditional text-based IDEs if I want to, so I get the best of both worlds."
  },
  {
    "objectID": "blog/posts/2022-07-28-nbdev2/index.html#what-we-learned-after-three-years-of-using-nbdev",
    "href": "blog/posts/2022-07-28-nbdev2/index.html#what-we-learned-after-three-years-of-using-nbdev",
    "title": "nbdev+Quarto: A new secret weapon for productivity",
    "section": "What we learned after three years of using nbdev",
    "text": "What we learned after three years of using nbdev\nWhile nbdev was originally developed to simplify the software development workflow for various fast.ai projects, we found that users wanted to extend nbdev to:\n\nWrite and publish blog posts, books, papers, and other types of documents with Jupyter Notebooks\nDocument existing codebases not written in nbdev\nAccommodate traditional Python conventions–for those constrained in how their code is organized and formatted\nPublish content using any static site generator\n\nWhile we created projects such as fastpages and fastdoc to accomplish some of these tasks, we realized that it would be better to have a single set of flexible tools to accomplish all of them. To this end, we were extremely excited to discover Quarto, an open-source technical publishing system built on pandoc.\nHamel: The more I used nbdev for creating Python modules, the more I wanted to use it for writing blogs and documenting existing codebases. The ability to customize the way notebooks are rendered (hiding vs. showing cells, stripping output, etc.), along with the facilities for including unit tests, made it my go-to authoring tool for all technical content. I’m excited that nbdev2 unlocks all of these possibilities for everyone!"
  },
  {
    "objectID": "blog/posts/2022-07-28-nbdev2/index.html#enter-quarto-a-pandoc-super-processor",
    "href": "blog/posts/2022-07-28-nbdev2/index.html#enter-quarto-a-pandoc-super-processor",
    "title": "nbdev+Quarto: A new secret weapon for productivity",
    "section": "Enter Quarto: A pandoc super-processor",
    "text": "Enter Quarto: A pandoc super-processor\nQuarto is a project that enables technical publishing with support for Jupyter Notebook, VSCode, Observable, and plaintext editors. Furthermore, Quarto enables the publishing of high-quality articles, reports, websites, and blogs in HTML, PDF, ePub, PowerPoint slides, and more. Quarto is maintained by RStudio, a company with a long history of products supporting literate programming, such as RMarkdown and RStudio.\nQuarto is built on top of Pandoc, a universal document converter that supports nearly any format you can think of. Pandoc achieves this seemingly magical feat by representing documents in a common abstract syntax tree (AST) that serves as the medium through which different formats can be translated. By extension, Quarto allows you to generate content in almost any format you wish! You can use pandoc filters to modify the AST and the output format, which allows you to use any static site generator you want, and programmatically modify and generate content.\nQuarto allows you to compose pandoc filters in a processing pipeline and apply them to specific documents or entire projects. You can also distribute filters as Quarto extensions, which makes Quarto extremely customizable.\nWe also find Quarto compelling because user interfaces such as comment directives (comments that start with #|) correlate with nbdev. In fact, we even learned that nbdev inspired Quarto in this regard! In general, Quarto and nbdev share many goals, and the Quarto team has been incredibly responsive to our suggestions. For example, the ability to create notebook filters to modify notebooks before rendering. Below is a screenshot of a Jupyter notebook rendered with Quarto and nbdev.\n\n\n\n\nQuarto rendering a Jupyter notebook written with nbdev\n\n\n\nFinally, Quarto supports more programming languages than just Python and has been adding new features and fixing bugs at an impressive speed. This gives us confidence that we will be able to expand nbdev to support more use cases in the future. We discuss some of these future directions in the closing section."
  },
  {
    "objectID": "blog/posts/2022-07-28-nbdev2/index.html#a-blazing-fast-notebook-kernel-execnb",
    "href": "blog/posts/2022-07-28-nbdev2/index.html#a-blazing-fast-notebook-kernel-execnb",
    "title": "nbdev+Quarto: A new secret weapon for productivity",
    "section": "A blazing fast notebook kernel: execnb",
    "text": "A blazing fast notebook kernel: execnb\nA core component of nbdev is executing and testing notebooks programmatically. It is important that this notebook runner executes with minimal overhead to maintain our goal of providing a delightful developer experience. This is why we built execnb, a lightweight notebook runner for Python kernels, which executes notebooks blazingly fast. Furthermore, execnb allows parameterized execution of notebooks.\nHamel: I have been an enthusiastic user of tools like papermill that programmatically run notebooks for use-cases like creating dashboards or enabling new kinds of machine learning workflows. I believe execnb unlocks even more possibilities with its ability to inject arbitrary code at any place in a notebook, as well as the ability to pass callbacks that run before and/or after cells are executed. This opens up possibilities to create new types of workflows with notebooks that I am excited about exploring in the near future."
  },
  {
    "objectID": "blog/posts/2022-07-28-nbdev2/index.html#towards-a-dialect-of-python-that-embraces-its-dynamic-nature",
    "href": "blog/posts/2022-07-28-nbdev2/index.html#towards-a-dialect-of-python-that-embraces-its-dynamic-nature",
    "title": "nbdev+Quarto: A new secret weapon for productivity",
    "section": "Towards a dialect of python that embraces its dynamic nature",
    "text": "Towards a dialect of python that embraces its dynamic nature\nOne way to understand nbdev is part of an ecosystem that is designed to embrace Python’s dynamic properties for REPL-driven software engineering. Similar to Clojure, our goal is to provide tools that remove all friction from using the REPL in your programming workflow. We believe that the REPL enhances developer workflows thanks to context-sensitive auto-completion, signature inspection, and documentation–all based on the actual state of your code, and none of which are available in IDEs that depend solely on static analysis. We have found that for this reason, nbdev, with its Jupyter notebook foundation, makes programming significantly more productive and enjoyable.\nOur efforts to support REPL-driven development and literate programming are not limited to nbdev. We maintain a number of libraries that extend python to bolster this programming experience. The most notable of these libraries is fastcore, which extends Python in terms of testing, documenting code, metaprogramming, attribute helpers, enhanced representations of objects, and notebook-friendly patching. This blog post offers a gentle introduction to fastcore. In addition to literate programming, fastcore encourages conventions such as brevity and efficient use of vertical space so you can accomplish more with significantly less code. For example, below is a simple decorator that enables notebook-friendly patching:\n\n\n\n@patch decorator from fastcore\n\n\nWe believe that this combination of a new developer workflow (nbdev), Python extensions (fastcore), and associated norms form a new dialect of Python that is centered on leveraging its dynamic nature–in contrast to an ever-growing trend toward static analysis. We suspect that this dialect of Python will be more productive for programmers in many scenarios. We are framing this ecosystem as a “dialect” as it is still very much Python and is approachable by anyone who is familiar with the language. Furthermore, despite nbdev’s notebook workflow, our tools generate plaintext modules that can be navigated and edited with text-based IDEs, allowing programmers to experience the best of both worlds, if they desire.\nHamel: I believe this framing of a Python dialect is key to properly understanding what nbdev is. While it may be tempting to get stuck on specific features or technical details of nbdev, it is useful to zoom out to understand the overall intent of creating a better workflow rather than conforming too rigidly to existing ones. A good analogy is TypeScript’s relationship with JavaScript: it is an extension of an existing programming language that supports a new way of programming. I encourage you to treat nbdev in a similar fashion: be willing to try new ways of programming and observe which tradeoffs resonate with you. At the very least, I believe nbdev is a fun way to experience a different way of writing software, which will broaden your horizons about programming in general, all without having to learn an entirely new programming language!"
  },
  {
    "objectID": "blog/posts/2022-07-28-nbdev2/index.html#the-future-of-nbdev",
    "href": "blog/posts/2022-07-28-nbdev2/index.html#the-future-of-nbdev",
    "title": "nbdev+Quarto: A new secret weapon for productivity",
    "section": "The future of nbdev",
    "text": "The future of nbdev\nWhile we are excited about nbdev2, we believe we have only scratched the surface of what’s possible. We are considering the following features:\n\nSupporting more languages beyond Python, such as Julia, R and JavaScript\nOffering interfaces for executing parameterized notebooks that mimic Python scripts\nExtensions for more static site generators and filters\nSupporting alternate testing backends, such as pytest\nSupporting a greater number of docstring formats, such as Google-style docstrings\nMore options to use plain-text or human readable notebook backends other than JSON\n\nIf you have interesting ideas about how nbdev can be extended, please drop and chat with us on discord or post a message in the forums."
  },
  {
    "objectID": "blog/posts/2022-07-28-nbdev2/index.html#how-you-can-get-started-with-nbdev",
    "href": "blog/posts/2022-07-28-nbdev2/index.html#how-you-can-get-started-with-nbdev",
    "title": "nbdev+Quarto: A new secret weapon for productivity",
    "section": "How you can get started with nbdev",
    "text": "How you can get started with nbdev\nOur project’s website is at nbdev.fast.ai, where we will be posting tutorials, examples, and more documentation in the coming days."
  },
  {
    "objectID": "blog/posts/2022-07-28-nbdev2/index.html#thank-you",
    "href": "blog/posts/2022-07-28-nbdev2/index.html#thank-you",
    "title": "nbdev+Quarto: A new secret weapon for productivity",
    "section": "Thank You",
    "text": "Thank You\nThis new version of nbdev was a team effort by many wonderful people. We want to highlight two people who have made outstanding contributions:\n\nWasim Lorgat was instrumental across different areas, including significant contributions to fastcore, execnb, and nbdev, as well as the implementation of the new nbdev home page. With Wasim’s help, we were able to push nbdev to a new level of functionality and quality.\nJJ Allaire is not only the CEO of RStudio but also the steward of Quarto. JJ was incredibly responsive and eager to work with us on nbdev and added many features to Quarto specifically with nbdev in mind, such as notebook filters. We were also astounded by the attention to detail and the pace at which bugs are addressed. This new version of nbdev would not have been possible without JJ’s help, and we are excited to continue to work with him.\n\nWe also want to thank the amazing fastai community, notably Isaac Flath, Benjamin Warner and Zach Mueller for their tireless work on this project."
  },
  {
    "objectID": "blog/posts/2022-07-28-nbdev2/index.html#a-conversation-with-jj-allaire",
    "href": "blog/posts/2022-07-28-nbdev2/index.html#a-conversation-with-jj-allaire",
    "title": "nbdev+Quarto: A new secret weapon for productivity",
    "section": "A conversation with JJ Allaire",
    "text": "A conversation with JJ Allaire\nTo celebrate the launch of nbdev v2 and Quarto, Jeremy sat down with the CEO of Posit (previously known as RStudio, the company behind Quarto), JJ Allaire, to talk about software development, scientific publishing, R, Python, literate programming, and much more."
  },
  {
    "objectID": "api/maker.html",
    "href": "api/maker.html",
    "title": "maker",
    "section": "",
    "text": "These functions let us find and modify the definitions of variables in Python modules."
  },
  {
    "objectID": "api/maker.html#helpers",
    "href": "api/maker.html#helpers",
    "title": "maker",
    "section": "",
    "text": "These functions let us find and modify the definitions of variables in Python modules."
  },
  {
    "objectID": "api/utils.display.html",
    "href": "api/utils.display.html",
    "title": "Utils.Display",
    "section": "",
    "text": "show_image\n\n show_image (im, ax=None, figsize=None, title=None, text=None,\n             fontsize=12, ctx=None, **kwargs)\n\nShow a PIL or PyTorch image on ax.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nim\n\n\n\n\n\nax\nNoneType\nNone\nif None, a new figure is created\n\n\nfigsize\nNoneType\nNone\nif None, the figure size is set to min of 5 and max of 1/32 of the image size\n\n\ntitle\nNoneType\nNone\ntitle of the image\n\n\ntext\nNoneType\nNone\ntext to be written on image\n\n\nfontsize\nint\n12\nfontsize of text\n\n\nctx\nNoneType\nNone\ncontext\n\n\nkwargs\n\n\n\n\n\nReturns\nAxes\n\nreturn matplotlib axis\n\n\n\n\nim2 = np.array(Image.open(TEST_IMAGE))\nax = show_image(im2, text='dog', figsize=(3,3))\n\n\n\n\n\n\n\nputtext\n\n puttext (img, text:str, pos=(40, 80), fontscale=2.0, thickness=2,\n          textcolor=(255, 255, 255), backcolor=(0, 0, 0))\n\nPlace text on the image, the default position is the center of the image\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nimg\n\n\n\n\n\ntext\nstr\n\ntext to be written on image\n\n\npos\ntuple\n(40, 80)\nposition of text\n\n\nfontscale\nfloat\n2.0\nfontscale of text\n\n\nthickness\nint\n2\nthickness of text\n\n\ntextcolor\ntuple\n(255, 255, 255)\ncolor of text\n\n\nbackcolor\ntuple\n(0, 0, 0)\ncolor of background\n\n\n\n\nim2 = np.array(Image.open(TEST_IMAGE))\nim2 = puttext(im2, 'dog')\nax = show_image(im2)"
  },
  {
    "objectID": "api/gstreamer.valve.html",
    "href": "api/gstreamer.valve.html",
    "title": "Gstreamer Valve",
    "section": "",
    "text": "Default parameters\nOveride these default parameters for application specific applications.\nThe code is shown below:\n\n\nCode\nfrom dataclasses import dataclass\n\n@dataclass\nclass DefaultParams():\n    camera_dev = \"CAM-0\"\n    cameras = {\n        \"CAM-0\": {\n            \"gst\": [\n                'videotestsrc pattern=smpte is-live=true ! tee name=t ',\n                't. ! queue leaky=2 ! videoconvert ! videorate drop-only=true ! video/x-raw,framerate=10/1,format=(string)BGR ! ',\n                '   videoconvert ! appsink name=sink emit-signals=true  sync=false async=false  max-buffers=2 drop=true ',\n                't. ! queue leaky=2 ! valve name=myvalve drop=true ! video/x-raw,format=I420,width=640,height=480 ! videoconvert ! x264enc ! rtph264pay ! udpsink host=127.0.0.1 port=5000',\n                ],\n            \"udp\": True,\n            \"host\": \"127.0.0.1\",\n            \"port\": 5000,\n        },\n        \"CAM-1\": {\n            \"gst\": [\n                'videotestsrc pattern=ball is-live=true ! tee name=t ',\n                't. ! queue leaky=2 ! videoconvert ! videorate drop-only=true ! video/x-raw,framerate=10/1,format=(string)BGR ! ',\n                '   videoconvert ! appsink name=sink emit-signals=true  sync=false async=false  max-buffers=2 drop=true ',\n                't. ! queue leaky=2 ! valve name=myvalve drop=true ! video/x-raw,format=I420,width=640,height=480 ! videoconvert ! x264enc ! rtph264pay ! udpsink host=127.0.0.1 port=5001',\n                ],\n            \"udp\": True,\n            \"host\": \"127.0.0.1\",\n            \"port\": 5001,\n        },\n        \"CAM-2\": {\n            \"gst\": [\n                'videotestsrc pattern=snow is-live=true ! tee name=t ',\n                't. ! queue leaky=2 ! videoconvert ! videorate drop-only=true ! video/x-raw,framerate=10/1,format=(string)BGR ! ',\n                '   videoconvert ! appsink name=sink emit-signals=true  sync=false async=false  max-buffers=2 drop=true ',\n                't. ! queue leaky=2 ! valve name=myvalve drop=true ! video/x-raw,format=I420,width=640,height=480 ! videoconvert ! x264enc ! rtph264pay ! udpsink host=127.0.0.1 port=5002',\n                ],\n            \"udp\": True,\n            \"host\": \"127.0.0.1\",\n            \"port\": 5002,\n        },\n        \"CAM-3\": {\n            \"gst\": [\n                'videotestsrc pattern=pinwheel is-live=true ! tee name=t ',\n                't. ! queue leaky=2 ! videoconvert ! videorate drop-only=true ! video/x-raw,framerate=10/1,format=(string)BGR ! ',\n                '  videoconvert ! appsink name=sink emit-signals=true  sync=false async=false  max-buffers=2 drop=true ',\n                't. ! queue leaky=2 ! valve name=myvalve drop=true ! video/x-raw,format=I420,width=640,height=480 ! videoconvert ! x264enc ! rtph264pay ! udpsink host=127.0.0.1 port=5003',\n                ],\n            \"udp\": True,\n            \"host\": \"127.0.0.1\",\n            \"port\": 5003,\n            },\n    \n       }\n\n    # socket address and port\n    mqqt_address='127.0.0.1'\n    src_port=1234\n\n\nAs an example for camera 0, DefaultParams.cameras[\"CAM-0\"][\"gst\"] is a list of gstreamer setup commands.\nThe default parameters list four gst videotestsrc each with a different pattern. The patterns are: - smpte, ball, snow, pinwheel.\nThe video is split with a tee into two streams 1. is streamed via an on / off valve to udp port 5000. 2. is streamed to an appsink for processing.\n\ngstcommand = DefaultParams().cameras[\"CAM-0\"][\"gst\"]\nprint(gstcommand)\n\n['videotestsrc pattern=smpte is-live=true ! tee name=t ', 't. ! queue leaky=2 ! videoconvert ! videorate drop-only=true ! video/x-raw,framerate=10/1,format=(string)BGR ! ', '   videoconvert ! appsink name=sink emit-signals=true  sync=false async=false  max-buffers=2 drop=true ', 't. ! queue leaky=2 ! valve name=myvalve drop=true ! video/x-raw,format=I420,width=640,height=480 ! videoconvert ! x264enc ! rtph264pay ! udpsink host=127.0.0.1 port=5000']\n\n\n\n\nGstreamer Receive Pipeline Class\nthe class is called with the gst command list and the address and port. frame_available is a flag that is set when a new frame is available.\n\n\nCode\n# https://github.com/gkralik/python-gst-tutorial/blob/master/basic-tutorial-4.py\n\nclass GstStream():\n    \"\"\"\"GstStream  class using gstreamer\n        Create and start a GStreamer pipe\n            gst_pipe = GstStream()\n        \"\"\"\n    \n    def __init__(self, name:str='CAM-0' # camera name\n                 , gstcommand:List=['videotestsrc ! autovideosink'] # gst command list\n                 , address:str='127.0.0.1'  # udp address\n                 , port:int=5000): # udp port\n        \n        Gst.init(None)\n        assert isinstance(name, str), \"name must be a string\"\n        self.name = name\n        assert isinstance(gstcommand, List), \"gstcommand must be a list\"\n        self.gstcommand = gstcommand\n        self.address = address\n        self.port = port\n\n        self.latest_frame = self._new_frame = None\n        self.start_gst()\n        self._thread = threading.Thread(target=self.msg_thread_func, daemon=True)\n        self._stop_thread = False\n        self._thread .start()\n        logger.info(\"GstStream started\")\n\n    def start_gst(self):\n        \"\"\" Start gstreamer pipeline and sink\n        \"\"\"\n        if self.gstcommand != []:\n            command = ' '.join(self.gstcommand)\n        else:\n            command = 'videotestsrc ! autovideosink'\n            command = \"videotestsrc ! tee name=t t. ! queue ! autovideosink \" +\\\n                       \" t. ! videoconvert ! video/x-raw,format=(string)BGR ! videoconvert ! \" +\\\n                       \" queue ! appsink name=sink emit-signals=true \"\n\n        # print (command)\n        self.pipeline = Gst.parse_launch(command)\n        self.appsink = self.pipeline.get_by_name('sink')\n        try:\n            self.appsink.connect('new-sample', self.callback)\n        except:\n            logger.error(\"Error connecting to callback\")\n            \n        self.pipeline.set_state(Gst.State.PLAYING)\n        self.bus = self.pipeline.get_bus()\n        \n    def msg_thread_func(self):   \n        \"Run thread\"\n        # Poll for messages on the bus (like EOS or ERROR), and handle them\n        while not self._stop_thread:\n            message = self.bus.timed_pop_filtered(100*Gst.MSECOND, Gst.MessageType.ANY)\n            if message is None:\n                continue\n    \n            if message.type == Gst.MessageType.EOS:\n                logger.info(\"End-Of-Stream reached.\")\n                break\n            elif message.type == Gst.MessageType.ERROR:\n                err, debug = message.parse_error()\n                logger.error(\"JN Error received from element %s: %s\" % (message.src.get_name(), err))\n                logger.error(\"Debugging information: %s\" % debug)\n                break\n        # Cleanup \n        logger.info(\"Stopping GstStream\")\n        self.pipeline.set_state(Gst.State.NULL)\n        \n    @staticmethod\n    def gst_to_opencv(sample):\n        \"Transform byte array into np array\"\n        buf = sample.get_buffer()\n        caps_structure = sample.get_caps().get_structure(0)\n        array = np.ndarray(\n            ( caps_structure.get_value('height'),caps_structure.get_value('width'), 3),\n            buffer=buf.extract_dup(0, buf.get_size()), dtype=np.uint8)\n        return array\n\n    def frame(self):\n        \"\"\" Get Frame\n        Returns:\n            np.ndarray: latest retrieved image frame\n        \"\"\"\n        if self.frame_available:\n            self.latest_frame = self._new_frame\n            # reset to indicate latest frame has been 'consumed'\n            self._new_frame = None\n        return self.latest_frame\n\n    def frame_available(self, \n                             timeout=2  # timeout in seconds\n                             )-&gt;bool:   # true if a new frame is available within timeout    \n        \"\"\"Wait for a new frame to be available\"\"\"\n        elapsetime = 0\n        while self._new_frame is None:\n            time.sleep(0.01)\n            elapsetime += 0.01\n            if elapsetime &gt; timeout:\n                return False\n        return True\n    \n            \n    def callback(self, sink):\n        sample = sink.emit('pull-sample')\n        # if not self.pause:\n        self._new_frame = self.gst_to_opencv(sample)\n\n        return Gst.FlowReturn.OK\n    \n    def close(self):\n        \"\"\"Close gstreamer pipeline\n        see https://github.com/gkralik/python-gst-tutorial/blob/master/basic-tutorial-1.py\n        \"\"\"\n        self.pipeline.send_event(Gst.Event.new_eos())   # Todo does not seem to stop pipeline\n        self.pipeline.set_state(Gst.State.NULL)\n        self._stop_thread = True\n        self._thread.join()\n        logger.info(\"GstStream closed\")\n\n        \n    def __enter__(self):\n        \"\"\"with context manager\"\"\"\n\n        return self  # This value is assigned to the variable after 'as' in the 'with' statement\n    \n    def __exit__(self, exc_type, exc_value, traceback):\n        \"\"\"with context manager\"\"\"\n        self.close()\n        # If an exception occurred, exc_type, exc_value, and traceback will be provided\n        # Returning False (or None) will propagate the exception\n        # Returning True will suppress it\n        return False\n\n\nTo run the above pipeline gst_pipeline = GstStream()\nTo close pipeline, run gst_pipeline.pipeline.close()\n\n\n\nGstStream.frame_available\n\n GstStream.frame_available (timeout=2)\n\nWait for a new frame to be available\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ntimeout\nint\n2\ntimeout in seconds\n\n\nReturns\nbool\n\ntrue if a new frame is available within timeout\n\n\n\n\ngstcommand = DefaultParams().cameras[\"CAM-0\"][\"gst\"]\nwith GstStream(\"CAM-0\", gstcommand) as gststream:\n    avail = gststream.frame_available()\n    print(f\"frame is avail = {avail}\")\n    # or \n    test_eq(gststream.frame_available(), True)\n\n17:58:45,270  INFO [894409507.py: 30] GstStream started\n17:58:45,382  INFO [894409507.py: 71] Stopping GstStream\n17:58:45,383  INFO [894409507.py:123] GstStream closed\n\n\nframe is avail = True\n\n\n\nValve gives the ability to pause the video stream\nTest the valve\n\ngstcommand = DefaultParams().cameras[\"CAM-0\"][\"gst\"]\nwith GstStream(\"CAM-0\", gstcommand) as gststream:\n    # avail = gststream.frame_available()\n    # print(f\"frame is avail = {avail}\")\n    gststream.set_valve_state(\"myvalve\", True)\n    test_eq(gststream.get_valve_state(\"myvalve\"), True) \n    gststream.set_valve_state(\"myvalve\", False)\n    test_eq(gststream.get_valve_state(\"myvalve\"), False)\n\n17:58:45,408  INFO [894409507.py: 30] GstStream started\n17:58:45,409  INFO [2691128992.py: 12] CAM-0: new drop state: True\n17:58:45,409  INFO [2691128992.py: 12] CAM-0: new drop state: False\n17:58:45,520  INFO [894409507.py: 71] Stopping GstStream\n17:58:45,521  INFO [894409507.py:123] GstStream closed\n\n\n\n\nPing IP address\nTest ping IP\n\ntest_eq(ping_ip(\"127.0.0.1\"), True)\ntest_eq(ping_ip(\"1.2.3.4\"), False)\n\n\n\nMQTT\n\n# Test Mqtt\nwith Mqtt(\"CAM-0\", None) as mqtt:\n    mqtt.wait_connection()\n    mqtt.client.publish(\"STREAM-CAMERA\", \"CAM-0\")\n    time.sleep(0.1)\n    assert mqtt.msg == \"CAM-0\"\n\n17:58:46,552  INFO [2975816526.py: 16] Connecting to 127.0.0.1\n17:58:46,552  INFO [2975816526.py: 49] Connected with result code 0\n17:58:46,563  INFO [2975816526.py: 36] Received message: CAM-0\n17:58:47,565  INFO [2975816526.py: 70] Closed mqtt_client client\n\n\n\n# Test with GstStream\n\nparams = DefaultParams()\ngstcommand = params.cameras[\"CAM-0\"][\"gst\"]\nwith  GstStream(\"CAM-0\", gstcommand) as video:\n    with Mqtt(\"CAM-0\", video) as mqtt:\n        mqtt.wait_connection()   # wait for connection\n        mqtt.client.publish(\"STREAM-CAMERA\", \"CAM-0\")\n        time.sleep(0.1)\n        vs = video.get_valve_state(\"myvalve\")\n        print(vs)\n        test_eq(vs, False)    # ie dont drop frames on this camera, drop on others\n\n        mqtt.client.publish(\"STREAM-CAMERA\", \"CAM-1\")\n        time.sleep(0.1)\n        vs = video.get_valve_state(\"myvalve\")\n        print(vs)\n        test_eq(vs, True)   # ie do drop frames on this camera, don't drop on CAM-1\n\n18:19:31,946  INFO [894409507.py: 30] GstStream started\n18:19:31,948  INFO [2975816526.py: 16] Connecting to 127.0.0.1\n18:19:31,950  INFO [2975816526.py: 49] Connected with result code 0\n18:19:31,960  INFO [2975816526.py: 36] Received message: CAM-0\n18:19:31,961  INFO [2691128992.py: 12] CAM-0: new drop state: False\n18:19:32,61   INFO [2975816526.py: 36] Received message: CAM-1\n18:19:32,61   INFO [2691128992.py: 12] CAM-0: new drop state: True\n18:19:33,62   INFO [2975816526.py: 70] Closed mqtt_client client\n18:19:33,183  INFO [894409507.py: 71] Stopping GstStream\n18:19:33,185  INFO [894409507.py:123] GstStream closed\n\n\nFalse\nTrue\n\n\n\n\n\nMain function for local testing\n\n\nCode\ndef main(camera=\"CAM-0\"):\n    params = DefaultParams()\n    gstcommand = params.cameras[camera][\"gst\"]\n    video = GstStream(camera, gstcommand)\n    cv2.namedWindow(camera, cv2.WINDOW_NORMAL)\n    mqtt = Mqtt(camera, video)\n\n    logger.info('Initialising stream...')\n    waited = 0\n    while not video.frame_available():\n        waited += 1\n        print('\\r  Frame not available (x{})'.format(waited), end='')\n        cv2.waitKey(30)\n\n    logger.info('\\nSuccess!\\nStarting streaming - press \"q\" to quit.')\n\n    print (\"Type q to stop\")\n    wait_time = 1\n    count = 0\n    while True:\n\n        if video.frame_available() and count % 10 == 0:\n            frame = video.frame().copy()\n            # # cv2.putText(frame, f'{frame_num:2d} {data_received}', (10, 30), cv2.FONT_HERSHEY_PLAIN, 1, (0, 0, 255), 2)\n            frame = resize(frame, width= 600)\n            cv2.imshow(camera, frame)\n            pass\n\n\n        if count % 1000 == 0:\n            print( count)\n        count += 1\n\n\n        k = cv2.waitKey(wait_time)\n\n        if k == ord('q') or k == ord('Q') or k == 27:\n            break\n\n        if k == ord('v'):\n            # Assuming you have a valve element named 'myvalve' in your pipeline\n            valve = video.pipeline.get_by_name(\"myvalve\")\n            current_drop_state = valve.get_property(\"drop\")\n            print(f\"current_drop_state {current_drop_state}\")\n            valve.set_property(\"drop\", not current_drop_state)\n            current_drop_state = valve.get_property(\"drop\")\n            print(f\"new_drop_state {current_drop_state}\", )\n\n            time.sleep(2)\n\n        if k == ord(' '):\n            if wait_time != 0:\n                wait_time = 0\n            else:\n                wait_time = 1\n\n        if k == ord('s'):\n            save = 0\n            save_path = Path(params.save_path) \n            save_path.mkdir(exist_ok=True)\n            pass\n\n    mqtt.close()\n    video.close()\n    cv2.destroyAllWindows()\n    logger.info(\"Closed all\")\n\n\n\nReceive on UDP with this Test :\nfrom first terminal run\n   gst-launch-1.0 udpsrc port=5000 ! application/x-rtp,encoding-name=H264,payload=96 ! \\\n           rtph264depay ! h264parse ! queue ! avdec_h264 ! xvimagesink sync=false async=false -e\nfrom second terminal run\n  mosquitto_pub -m \"CAM-0\" -t \"STREAM-CAMERA\"\n  mosquitto_pub -m \"CAM-1\" -t \"STREAM-CAMERA\"\n\n\n\nTest with two cameras from terminal\nThe idea is to run the 4 gst pipelines in direent processes\n\n\nCode\nfrom multiprocessing import Process   # you will need to import Process from multiprocessing\n\nif __name__ == '__main__':\n\n    cams = []\n    params = DefaultParams()\n    for cam in list(params.cameras.keys())[:2]:\n        logger.info(\"Starting Cam: {cam}\")\n        p = Process(target=main, args=(cam,))\n        p.start()\n        cams.append(p)\n\n    for p in cams:\n        p.join()\n\n\n17:59:05,303  INFO [475948639.py: 13] Starting Cam: {cam}\n17:59:05,308  INFO [475948639.py: 13] Starting Cam: {cam}\n17:59:05,313  INFO [894409507.py: 30] GstStream started\n17:59:05,320  INFO [894409507.py: 30] GstStream started\n17:59:05,442  INFO [2975816526.py: 16] Connecting to 127.0.0.1\n17:59:05,442  INFO [2975816526.py: 16] Connecting to 127.0.0.1\n17:59:05,444  INFO [3123209435.py: 11] Initialising stream...\n17:59:05,444  INFO [3123209435.py: 11] Initialising stream...\n17:59:05,444  INFO [2975816526.py: 49] Connected with result code 0\n17:59:05,444  INFO [2975816526.py: 49] Connected with result code 0\n17:59:05,444  INFO [3123209435.py: 18] \nSuccess!\nStarting streaming - press \"q\" to quit.\n17:59:05,444  INFO [3123209435.py: 18] \nSuccess!\nStarting streaming - press \"q\" to quit.\n17:59:14,454  INFO [2975816526.py: 70] Closed mqtt_client client\n17:59:14,556  INFO [894409507.py: 71] Stopping GstStream\n17:59:14,558  INFO [894409507.py:123] GstStream closed\n17:59:14,562  INFO [3123209435.py: 69] Closed all\n17:59:15,482  INFO [2975816526.py: 70] Closed mqtt_client client\n17:59:15,585  INFO [894409507.py: 71] Stopping GstStream\n17:59:15,588  INFO [894409507.py:123] GstStream closed\n17:59:15,595  INFO [3123209435.py: 69] Closed all\n\n\nType q to stopType q to stop\n\n0\n0"
  },
  {
    "objectID": "contributing/doc_walkthrough.html",
    "href": "contributing/doc_walkthrough.html",
    "title": "Documentation Walkthrough",
    "section": "",
    "text": "The written tutorial below shows you how to create a Python package from scratch using nbdev.\nAlternatively, you can watch this video tutorial where Jeremy Howard and Hamel Husain guide you through a similar process step by step:"
  },
  {
    "objectID": "contributing/doc_walkthrough.html#installation",
    "href": "contributing/doc_walkthrough.html#installation",
    "title": "Documentation Walkthrough",
    "section": "Installation",
    "text": "Installation\nYou’ll need the following software to complete the tutorial, read on for specific installation instructions:\n\nPython\nA Python package manager: we recommend conda or pip\nJupyter Notebook\nnbdev\nQuarto\n\nIf you haven’t worked with Python before, we recommend getting started with the Anaconda Individual Edition and using the conda package manager.\nNote that you will only need to follow the steps in the installation section once per environment. If you create a new repo, you won’t need to redo these.\n\nInstall JupyterLab\nLaunch a terminal and install JupyterLab by entering:\nconda install -c conda-forge -y jupyterlab\n…or\npip install jupyterlab\n…if you’re using the pip package manager.\nYou can now launch Jupyter by entering:\njupyter lab\nThis should open JupyterLab in a new browser tab:\n\n\n\n\n\n\n\nInstall nbdev\nThe next step is to install nbdev itself. JupyterLab comes with its own terminal, so we’ll use that moving forward.\nIn the Launcher, scroll down to the “Other” section, then click “Terminal”. If the Launcher isn’t opened, you can open it by clicking “File” → “New Launcher”.\nA new tab should open with a blank terminal – it might not look exactly the same, depending on how your shell is configured:\n\n\n\n\n\nFor Mac and Linux, enter:\nconda install -c fastai -y nbdev\n…or for Mac, Linux and Windows:\npip install nbdev\n…if you’re using pip.\n\n\nInstall Quarto\nnbdev provides a command to install the latest version of Quarto. In the terminal, enter:\nnbdev_install_quarto\nYour password may be requested at this point. Since nbdev is open source, you can read the source code of this command to verify that it isn’t doing anything malicious. Or, if you prefer, you may instead follow Quarto’s official installation instructions.\n\n\nInstall Quarto JupyterLab extension\nQuarto provides its own JupyterLab extension that allows it to render Quarto markdown content.\nFor example, here is their notebook demonstrating some of its features:\n\nInstall the extension by entering:\npip install jupyterlab-quarto\nNote that the jupyterlab-quarto package is not currently available via conda.\n\nYou’re all setup and ready to go! Installing these tools may take some time, but you’ll only need to do it once. Next, we’ll setup an nbdev repo for your specific project."
  },
  {
    "objectID": "contributing/doc_walkthrough.html#first-steps",
    "href": "contributing/doc_walkthrough.html#first-steps",
    "title": "Documentation Walkthrough",
    "section": "First steps",
    "text": "First steps\nBy the end of this section you’ll have your own nbdev repo with tests, continuous integration, streamlined PyPI & conda packaging, and a documentation website.\n\nCreate an empty GitHub repo\nCreate an empty GitHub repo using the convenient link github.com/new. If you get stuck, you might find GitHub’s Create a repo page helpful.\nRemember to add a description, since nbdev will use that later. Don’t add a README file, .gitignore, or license just yet.\nIf you’re using the web interface, it should look something like this (with your own repository name and descrpition) before you click “Create Repository”:\n\n\n\n\n\nYou should then be redirected to your new repo:\n\n\n\n\n\n\n\n\n\n\n\nTry GitHub’s powerful CLI\n\n\n\n\n\nGitHub’s web interface is a great way to get started. As you grow more experienced, you might want to explore the GitHub CLI (command line interface). We often prefer to use command line tools for repetitive tasks where we’re likely to make mistakes. Having those tasks written as small scripts in your terminal means that you can repeat them with little effort.\n\n\n\n\n\nInitialise your repo with nbdev\nNow clone your repo from the Jupyter terminal you started earlier (or create a new terminal following those instructions if needed). If you get stuck here, you might find GitHub’s Cloning a repository page helpful.\nSince we created a repo named nbev-hello-world with the fastai user, we can clone it as follows:\ngit clone https://github.com/fastai/nbdev-hello-world.git\nThen cd (change directory) to our repo:\ncd nbdev-hello-world\nYou may have seen this message while cloning:\nYou appear to have cloned an empty repository.\n…since the repo is completely empty. Let’s add some files!\nnbdev provides the nbdev_new command to initialise an empty git repository. It’ll infer information about your project from git and GitHub, and ask you to input anything remaining. It will create files in your repo that:\n\nStreamline publishing Python packages to PyPI and conda.\nConfigure Quarto for publication-grade technical documentation.\nSetup GitHub actions to test notebooks and build and deploy Quarto docs to GitHub pages.\n\nInitialise your nbdev repo by entering:\nnbdev_new\nIt may ask you to enter information that it couldn’t infer from git or GitHub.\n\n\n\n\n\n\nNote\n\n\n\nnbdev_new assumes that your package name is the same as your repo name (with - replaced by _). Use the --lib_name option if that isn’t the case.\n\n\nDouble-check your settings.ini file to ensure that it has all of the correct information. Then commit and push your additions to GitHub:\ngit add .\ngit commit -m'Initial commit'\ngit push\n\n\nEnable GitHub Pages\nnbdev hosts your docs on GitHub Pages—an excellent (and free!) way to host websites.\n\n\n\n\n\n\nNote\n\n\n\nnbdev uses GitHub Pages by default because its easily accessible. However, you can use any host you like. See these docs for more information.\n\n\nYou need to enable GitHub Pages for your repo by clicking on the “Settings” tab near the top-right of your repo page, then “Pages” on the left, then setting the “Branch” to “gh-pages”, and finally clicking “Save”.\nIt should look similar to this after you click “Save”:\n\n\n\n\n\nNow it’s time to see all of the goodies nbdev gives you!\n\n\nCheck out your workflows\nOpen GitHub Actions by clicking the “Actions” tab near the top of your repo page. You should see two workflow runs:\n\n\n\n\n\nIf you opened this page shortly after pushing your initial commit, the runs may not have a green check (✅) because they’re still “In progress” or “Queued”. That’s no problem, they shouldn’t take much more than a minute to complete.\nIf you see a red cross (❌), that means something failed. Click on the cross, then click “Details”, and you’ll be able to see what failed. If you can’t figure out what’s wrong, search the forum in case someone else resolved the same issue, otherwise create a new post describing your issue in as much detail as you can, and we’ll try our best to help you. Remember that including a link to an actual repo and/or GitHub Action is the best way for us to quickly identify what’s wrong.\nWhat do these workflows do?\n\nCI – The CI (continuous integration) workflow streamlines your developer workflow, particularly with multiple collaborators. Every time you push to GitHub, it ensures that:\n\nYour notebooks and libraries are in sync\nYour notebooks are cleaned of unwanted metadata (which pollute pull requests and git histories and lead to merge conflicts)\nYour notebook tests all pass\n\nDeploy to GitHub Pages – Builds your docs with Quarto and deploys it to GitHub Pages.\n\nWe provide these basic workflows out-of-the-box, however, you can edit their corresponding YAML files in the .github/workflows/ folder to your liking.\n\n\nCheck out your docs\nWhen you enable GitHub Pages you should see a new workflow run: “pages build and deployment”. As the name suggests, this workflow deploys your website contents to GitHub Pages.\n\n\n\n\n\nWait for the workflow run to complete, then open your website. By default it should be available at: https://{user}.github.io/{repo}. For example, you can view fastai’s nbdev-hello-world docs at https://fastai.github.io/nbdev-hello-world.\n\n\n\n\n\n\n\nRecap\nYou now have a base nbdev repo with continuous integration and hosted documentation! Here’s a recap of the steps you took:\n\nCreated a GitHub repo (with GitHub Pages enabled)\nInitialised your repo with nbdev_new\nPushed to GitHub."
  },
  {
    "objectID": "contributing/doc_walkthrough.html#make-your-first-edit",
    "href": "contributing/doc_walkthrough.html#make-your-first-edit",
    "title": "Documentation Walkthrough",
    "section": "Make your first edit",
    "text": "Make your first edit\nIn this section, you’ll make your first edit to the repo you created in First steps.\n\nInstall hooks for git-friendly notebooks\nStep one when working with Jupyter notebooks in a new repo is to install nbdev’s hooks (you can think of “hooks” as plugins or extensions to an application).\nInstall them by entering this command in your terminal:\nnbdev_install_hooks\n\n\n\n\n\n\nNote\n\n\n\nThe clean hook currently only supports Jupyter Notebook and JupyterLab. If you’re using VSCode, you can try the experimental nbdev VSCode extension. Otherwise, you might also want to try nbdev’s pre-commit hooks.\n\n\nSee Git-friendly Jupyter for more about how nbdev hooks work and how to customise them. Here’s a short summary:\n\nFix broken notebooks due to git merge conflicts so that they can be opened and resolved directly in Jupyter.\nEach time you save a Jupyter notebook, automatically clean unwanted metadata to remove unnecessary changes in pull requests and reduce the chance of git merge conflicts.\nAutomatically trust notebooks in the repo so that you can view widgets from collaborators’ commits. For this reason, you should not install hooks into a repo you don’t trust.\n\n\n\n\n\n\n\nTip\n\n\n\nnbdev’s git hooks work on any git repo, even if it doesn’t use the broader nbdev system.\n\n\n\n\nBuild your library\nYou should now create your package from your notebook by running:\nnbdev_export\nThis will create Python modules for your notebooks. These modules will make up the contents of your Python package.\n\n\nInstall your package\nYou might have noticed that nbdev_new created a Python package in your repo. In our case, it was automatically named nbdev_hello_world by using our repo name nbdev-hello-world and replacing - with _ to make it a valid Python package.\nThe next step is to install your package by entering this into your terminal:\npip install -e '.[dev]'\nThis is the recommended way to make a Python package importable from anywhere in your current environment:\n\n-e – short for “editable”, lets you immediately use changes made to your package without having to reinstall, which is convenient for development.\n. – refers to the current directory.\n[dev] – includes “development” requirements: other packages that your notebooks use solely for documentation or testing.\n\n\n\nPreview your docs\nnbdev is an interactive programming environment that values fast feedback loops. The nbdev_preview command helps achieve this by using Quarto to render your docs on your computer and keep them updated as your edit your notebooks.\nStart the preview by entering this into your terminal:\nnbdev_preview\nIt may say Preparing to preview for a few seconds while it gets started, and will eventually display something like:\nWatching files for changes\nBrowse at http://localhost:3000/\nClick the link to open the preview in a new browser tab. It should look exactly like your online docs.\n\n\n\n\n\n\nTip\n\n\n\nWe often find it useful to keep a preview window open on the side while we’re editing our notebooks in Jupyter.\n\n\n\n\nEdit 00_core.ipynb\nNow, open the nbs/00_core.ipynb file (generated by running nbdev_new earlier) in Jupyter. You don’t have to start your notebook names with a number, but we find it helpful to show the order that your project should be read in – even though it could have been created in a different order.\n\nAdd your own frontmatter\nYou’ll see something that looks a bit like this:\n\ncore\n\nFill in a module description here\n\n#| default_exp core\n\nLet’s explain what these special cells means:\n\nThe first is a markdown cell with nbdev’s markdown frontmatter syntax that defines notebook metadata used by Quarto, our documentation engine (see the frontmatter reference page for more). It contains:\n\nH1 header (“core”) – defining the page title\nQuote (“Fill in a module description here”) – defining the page description\n\nThe second is a code cell with a directive default_exp which decides which module this notebook will export to (see the Directives explanation for more). Currently, it exports to the core module.\n\nNext, rename the notebook, replace the title and description, and change the default export module for your own project.\nOnce you’re done, save the notebook. The live preview started in the previous section should update with your latest changes.\nRerun all cells in your notebook to ensure that they work, and to export the updated modules.\n\n\n\n\n\n\nTip\n\n\n\nWe find the “restart kernel and run all cells” Jupyter command (the ⏩ button) so invaluable that we bind it to a keyboard shortcut. A common criticism of notebooks is that out-of-order execution leads to irreproducible notebooks. In our experience, making “restart and rerun” a habit solves this problem.\n\n\nRunning the notebook exports Python modules because of the last cell which contains:\n#| hide\nimport nbdev; nbdev.nbdev_export()\nWhat does this mean?\n\n#| hide is a directive (like #| default_exp) which excludes a cell from both your exported module and docs\nnbdev_export is the command used to export your notebooks to Python modules.\n\nWe recommend including a cell like this at the bottom of all of the notebooks you want to export.\n\n\n\n\n\n\nWarning\n\n\n\nRemember to delete any unused modules that aren’t exported by a notebook or otherwise needed by your package. This is likely to happen if you change the default export of a notebook – nbdev doesn’t remove the old module. This is intended, since nbdev is designed to work with hybrid packages that use .py modules (with no corresponding notebook) as well as those exported from notebooks.\n\n\n\n\nAdd your own function\nAdd a new code cell below the #| default_exp cell with a function. For example:\n#| export\ndef say_hello(to):\n    \"Say hello to somebody\"\n    return f'Hello {to}!'\nNotice how it includes #| export at the top – this is a directive (like #| default_exp) that tells nbdev to include the cell in your exported module and in your documentation.\nThe documentation should look like this:\n\n\n\nsay_hello\n\n say_hello (to)\n\nSay hello to somebody\n\n\n\n\nAdd your own examples, tests, and docs\nOne of the superpowers of notebook-driven development is that you can very easily add examples, tests, and documentation right below your code.\nInclude regular code cells, and they’ll appear (with output) in your docs, for example:\n\nsay_hello(\"Isaac\")\n\n'Hello Isaac!'\n\n\nThis is a test too! When you run nbdev_test it will execute this cell (and all other test cells) and fail if they raise any exceptions.\nFor tests, it’s preferred to use more explicit asserts:\n\nassert say_hello(\"Hamel\") == \"Hello Hamel!\"\n\n…or functions from fastcore.test, which behave like assert but also display the actual and expected values if they differ:\n\nfrom fastcore.test import *\n\n\ntest_eq(say_hello(\"Hamel\"), \"Hello Hamel!\")\n\nAnother superpower of notebook-driven development is that your examples can include plots, images, and even JavaScript widgets. For example, here’s an SVG circle:\n\nfrom IPython.display import display,SVG\n\n\ndisplay(SVG('&lt;svg height=\"100\" xmlns=\"http://www.w3.org/2000/svg\"&gt;&lt;circle cx=\"50\" cy=\"50\" r=\"40\"/&gt;&lt;/svg&gt;'))\n\n\n\n\n\n\n\nPrepare your changes\nBefore commiting your changes to GitHub we recommend running nbdev_prepare in the terminal, which bundles the following commands:\n\nnbdev_export: Builds the .py modules from Jupyter notebooks\nnbdev_test: Tests your notebooks\nnbdev_clean: Cleans your notebooks to get rid of extreanous output for git\nnbdev_readme: Updates your repo’s README.md file from your index notebook.\n\n\n\nEdit index.ipynb\nNow you’re ready to personalize your documentation home page and README.md file; these are both generated automatically from index.ipynb. Open Jupyter, then click on nbs/index.ipynb to open it.\nWe recommend including a longer description about what your package does, how to install it, and how to use it (with a few examples which import and use your package). Remember, examples can be code cells with real outputs rather than plain markdown text – they’ll double as tests too!\n\n\nPush to Github\nYou can now commit and push your changes to GitHub. As we mentioned before, always remember to run nbdev_prepare before you commit to ensure your modules are exported and your tests pass. You can use git status to check which files have been generated or changed. Then:\ngit add .\ngit commit -m 'Add `say_hello`; update index' # Update this text with your own message\ngit push\nThis will kick-off your GitHub Actions. Wait a minute or two for those to complete, then check your updated repo and documentation.\n\n\nRecap\nCongratulations, you’ve used all of the basics needed to build delightful projects with nbdev! Here’s a recap of the steps you took:\n\nInstalled hooks for git-friendly notebooks with nbdev_install_hooks\nInstalled your package with pip install -e '.[dev]'\nPreviewed your docs with nbdev_preview\nAdded your own frontmatter, function, tests, and docs to nbs/00_core.ipynb\nPrepared your changes with nbdev_prepare\nUpdated nbs/index.ipynb with your own information\nPushed to GitHub.\n\nRead on to learn about more advanced nbdev functionality. Also see our explanations for deep-dives on specific topics, as well as our other tutorials."
  },
  {
    "objectID": "contributing/doc_walkthrough.html#advanced-functionality",
    "href": "contributing/doc_walkthrough.html#advanced-functionality",
    "title": "Documentation Walkthrough",
    "section": "Advanced functionality",
    "text": "Advanced functionality\n\nAdd a class\nCreate a class in 00_core.ipynb as follows:\n#| export\nclass HelloSayer:\n    \"Say hello to `to` using `say_hello`\"\n    def __init__(self, to): self.to = to\n        \n    def say(self):\n        \"Do the saying\"\n        return say_hello(self.to)\nThis will automatically appear in the docs like this:\n\n\n\nHelloSayer\n\n HelloSayer (to)\n\nSay hello to to using say_hello\n\nDocument with show_doc\nHowever, methods aren’t automatically documented. To add method docs, use show_doc:\nshow_doc(HelloSayer.say)\n\n\n\n\nHelloSayer.say\n\n HelloSayer.say ()\n\nDo the saying\nAnd add some examples and/or tests:\n\no = HelloSayer(\"Alexis\")\no.say()\n\n'Hello Alexis!'\n\n\n\n\nAdd links with backticks\nNotice above there is a link from our new class documentation to our function. That’s because we used backticks in the docstring:\n    \"Say hello to `to` using `say_hello`\"\nThese are automatically converted to hyperlinks wherever possible. For instance, here are hyperlinks to HelloSayer and say_hello created using backticks.\n\n\nSet up autoreload\nSince you’ll be often updating your modules from one notebook, and using them in another, it’s helpful if your notebook automatically reads in the new modules as soon as the Python file changes. To make this happen, just add these lines to the top of your notebook:\n%load_ext autoreload\n%autoreload 2\n\n\nSet up prerequisites\nIf your module requires other modules as dependencies, you can add those prerequisites to your settings.ini in the requirements section. The requirements should be separated by a space and if the module requires at least or at most a specific version of the requirement this may be specified here, too.\nFor example if your module requires the fastcore module of at least version 1.0.5, the torchvision module of at most version 0.7 and any version of matplotlib, then the prerequisites would look like this:\nrequirements = fastcore&gt;=1.0.5 torchvision&lt;0.7 matplotlib\nIn addition to requirements you can specify dependencies with other keywords that have different scopes. Below is a list of all possible dependency keywords:\n\nrequirements: Passed to both pip and conda setup\npip_requirements: Passed to pip setup only\nconda_requirements: Passed to conda setup only\ndev_requirements: Passed to pip setup as a development requirement\n\nFor more information about the format of dependencies, see the pypi and conda docs on creating specifications in setup.py and meta.yaml, respectively.\n\n\nSet up console scripts\nBehind the scenes, nbdev uses that standard package setuptools for handling installation of modules. One very useful feature of setuptools is that it can automatically create cross-platform console scripts. nbdev surfaces this functionality; to use it, use the same format as setuptools, with whitespace between each script definition (if you have more than one).\nconsole_scripts = nbdev_export=nbdev.cli:nbdev_export\n\n\nUpload to pypi\nIf you want people to be able to install your project by just typing pip install your-project then you need to upload it to pypi. The good news is, we’ve already created a fully pypi compliant installer for your project! So all you need to do is register at pypi (click “Register” on pypi) if you haven’t previously done so, and then create a file called ~/.pypirc with your login details. It should have these contents:\n[pypi]\nusername = your_pypi_username\npassword = your_pypi_password\nAnother thing you will need is twine, so you should run once\npip install twine\nTo upload your project to pypi, just type nbdev_pypi in your project root directory. Once it’s complete, a link to your project on pypi is displayed.\n\n\nUpload to conda\nSimilar to pip install support, we have provided an anaconda compliant installer to upload your project to anaconda. Once uploaded, your package can be installed by typing conda install -c your_anaconda_username your-project.\nYou need to register at anaconda (fill out the form to Sign Up) which will create a username and password. You will then need to install the following packages\npip install anaconda-client conda-build conda-verify\nBefore running the anaconda uploader, you need to login to conda using the CLI command (you will be prompted to enter your username and password)\nanaconda login\nTo upload to anaconda, just type nbdev_conda in your project root directory.\n\n\nUpload to pypi and conda\nThe command nbdev_release_both from the root of your nbdev repo will upload your project to both conda and pypi.\n\n\nInstall collapsible headings and toc2\nThere are two jupyter notebook extensions that I highly recommend when working with projects like this. They are:\n\nCollapsible headings: This lets you fold and unfold each section in your notebook, based on its markdown headings. You can also hit left to go to the start of a section, and right to go to the end\nTOC2: This adds a table of contents to your notebooks, which you can navigate either with the Navigate menu item it adds to your notebooks, or the TOC sidebar it adds. These can be modified and/or hidden using its settings.\n\n\n\nMath equation support\nnbdev supports equations (using Quarto). You can include math in your notebook’s documentation using the following methods.\nUsing $$, e.g.:\n$$\\sum_{i=1}^{k+1}i$$\nWhich is rendered as:\n\n\\[\\sum_{i=1}^{k+1}i\\]\n\nUsing $, e.g.:\nThis version is displayed inline: $\\sum_{i=1}^{k+1}i$ . You can include text before and after.\nWhich is rendered as:\n\nThis version is displayed inline: \\(\\sum_{i=1}^{k+1}i\\) . You can include text before and after.\n\nFor more information, see the Quarto Docs\n\n\nLook at nbdev “source” for more ideas\nDon’t forget that nbdev itself is written in nbdev! It’s a good place to look to see how fast.ai uses it in practice, and get a few tips. You’ll find the nbdev notebooks here in the nbs folder on Github.\n\n\nQuarto Features\nnbdev supports most Quarto features. We encourage you to read the Quarto documentation to discover all the features available to you. For example, this is how you can incorporate mermaid charts:\n\n\n\n\nflowchart LR\n  A[Hard edge] --&gt; B(Round edge)\n  B --&gt; C{Decision}\n  C --&gt; D[Result one]\n  C --&gt; E[Result two]\n\n\n\n\n\nHere is another example of using Graphviz:\n\n\n\n\n\n\n\nG\n\n  \n\nrun\n\n run   \n\nintr\n\n intr   \n\nrun–intr\n\n   \n\nkernel\n\n kernel   \n\nrun–kernel\n\n   \n\nrunbl\n\n runbl   \n\nintr–runbl\n\n   \n\nrunbl–run\n\n   \n\nzombie\n\n zombie   \n\nkernel–zombie\n\n   \n\nsleep\n\n sleep   \n\nkernel–sleep\n\n   \n\nrunmem\n\n runmem   \n\nkernel–runmem\n\n   \n\nsleep–runmem\n\n   \n\nswap\n\n swap   \n\nsleep–swap\n\n   \n\nrunswap\n\n runswap   \n\nswap–runswap\n\n   \n\nrunswap–runmem\n\n   \n\nnew\n\n new   \n\nrunswap–new\n\n   \n\nnew–runmem\n\n  \n\n\n\n\n\nIt is worth taking a look at the documentation for figures, callouts, markdown, widgets, layouts, conditional content and quarto extensions to name a few useful things we have encountered."
  },
  {
    "objectID": "contributing/why_nbdev.html",
    "href": "contributing/why_nbdev.html",
    "title": "Why nbdev",
    "section": "",
    "text": "Popular Python documentation standards such as numpy docstrings and sphinx facilitate documentation of source code with docstrings, which are limited in their expressiveness and functionality. Notebooks, on the other hand, offer a richer medium for authoring documentation (with markdown and code cells) compared to docstrings, and unlock new ways of documenting your code that are otherwhise infeasible.\nFurthermore, traditional testing frameworks such as pytest and unittest encourage writing tests in a separate context that is disjointed from the associated source code and documentation. With nbdev, you write tests in the same context as your source code and documentation, such that tests can optionally become part of the narrative within your documentation.\nSince nbdev allows your colleagues and users to view the tests, code and documentation in a single context with a REPL that invites experimentation, the way you author code, documentation and tests in nbdev are very different than traditional software development workflows.\nIn Notebook Best Practices we compare a function coded, tested, and documented in nbdev versus ordinary .py files. Here are a few of the challenges we faced with other approaches that led us to using nbdev. In .py files:\n\nDocstrings repeat information that is already contained in the function signature, such as names of parameters, default values, and types\nExamples are manually entered. This requires the author to copy and paste both the code and outputs. Furthermore, the author must manually re-enter or change these examples anytime the code changes, which is an error-prone process\nExamples are limited to short code snippets and cannot contain rich output like plots or graphics\nExamples cannot have prose interleaved with code except for code comments\nReaders of your code must copy and paste contents of the docstring if they wish to reproduce the examples."
  },
  {
    "objectID": "contributing/docs.html",
    "href": "contributing/docs.html",
    "title": "Docs Website",
    "section": "",
    "text": "There are two mediums in which you can author documentation in nbdev:\n\nJupyter Notebooks\nQuarto Markdown (.qmd)\n\nFor most cases, you will use Jupyter Notebooks. However, you may choose to author a document in Quarto Markdown if there is no code on that particular page. When in doubt, we recommend using notebooks as they are more versatile.\nIn the case of notebooks, nbdev pre-processes them to add, remove or change the content before passing it to Quarto. In some cases, nbdev even executes certain cells in order to render the documentation properly. The mechanics of this are discussed in the Notebook Processor section below.\nFor markdown files, Quarto renders these directly.\n\n\n\nNbdev does special pre-processing on notebooks based on the following:\n\nDirectives: Directives are special comments that allow you to perform operations on cells. For example, the comment #|hide allows you to hide cell inputs and outputs. You can read more about directives on this page. Directives that are unique to nbdev and not supported by Quarto are removed from the notebook before being passed to Quarto.\nFront Matter: Front matter allows you to specify document-level options so you don’t have to repeat them on each cell. (Similarly, _quarto.yml allows you to specify project-level options.) You can read more about Quarto front-matter here.\n\nThe directives and front-matter are used by a Processing Pipeline to transform notebooks. Many of these pre-processing steps are defined in nbdev.processors, which are then run by nbdev.process.NBProcessor. Some of these pre-processing steps involve running code (with execnb) in order to dynamically render API documentation. This process is explained in the How show_doc works section below.\nWhen generating your docs site, the intermediate output of these pre-processed notebooks and other quarto project files are saved into a directory named _proc/ at the root of your repo. You can inspect the _proc/ directory in order to debug or understand how notebooks are pre-processed.\n\n\n\nQuarto is the mechanism nbdev uses to generate web pages from notebooks. It is useful to visit the Quarto docs and understand how it works. nbdev automatically generates the Quarto configuration files _quarto.yml and sidebar.yml for you.\nYou can override any settings in _quarto.yml by defining a custom.yml file. This is explained further in the Customizing Quarto section. We explain how to customize your sidebar in the Customizing The Sidebar section.\n\n\n\nQuarto has a built-in static site generator that will generate HTML, Javascript and CSS files. These files will be placed in the doc_path directory as specified in your project’s settings.ini file, which is _docs/ by default."
  },
  {
    "objectID": "contributing/docs.html#concepts",
    "href": "contributing/docs.html#concepts",
    "title": "Docs Website",
    "section": "",
    "text": "There are two mediums in which you can author documentation in nbdev:\n\nJupyter Notebooks\nQuarto Markdown (.qmd)\n\nFor most cases, you will use Jupyter Notebooks. However, you may choose to author a document in Quarto Markdown if there is no code on that particular page. When in doubt, we recommend using notebooks as they are more versatile.\nIn the case of notebooks, nbdev pre-processes them to add, remove or change the content before passing it to Quarto. In some cases, nbdev even executes certain cells in order to render the documentation properly. The mechanics of this are discussed in the Notebook Processor section below.\nFor markdown files, Quarto renders these directly.\n\n\n\nNbdev does special pre-processing on notebooks based on the following:\n\nDirectives: Directives are special comments that allow you to perform operations on cells. For example, the comment #|hide allows you to hide cell inputs and outputs. You can read more about directives on this page. Directives that are unique to nbdev and not supported by Quarto are removed from the notebook before being passed to Quarto.\nFront Matter: Front matter allows you to specify document-level options so you don’t have to repeat them on each cell. (Similarly, _quarto.yml allows you to specify project-level options.) You can read more about Quarto front-matter here.\n\nThe directives and front-matter are used by a Processing Pipeline to transform notebooks. Many of these pre-processing steps are defined in nbdev.processors, which are then run by nbdev.process.NBProcessor. Some of these pre-processing steps involve running code (with execnb) in order to dynamically render API documentation. This process is explained in the How show_doc works section below.\nWhen generating your docs site, the intermediate output of these pre-processed notebooks and other quarto project files are saved into a directory named _proc/ at the root of your repo. You can inspect the _proc/ directory in order to debug or understand how notebooks are pre-processed.\n\n\n\nQuarto is the mechanism nbdev uses to generate web pages from notebooks. It is useful to visit the Quarto docs and understand how it works. nbdev automatically generates the Quarto configuration files _quarto.yml and sidebar.yml for you.\nYou can override any settings in _quarto.yml by defining a custom.yml file. This is explained further in the Customizing Quarto section. We explain how to customize your sidebar in the Customizing The Sidebar section.\n\n\n\nQuarto has a built-in static site generator that will generate HTML, Javascript and CSS files. These files will be placed in the doc_path directory as specified in your project’s settings.ini file, which is _docs/ by default."
  },
  {
    "objectID": "contributing/docs.html#overview",
    "href": "contributing/docs.html#overview",
    "title": "Docs Website",
    "section": "Overview",
    "text": "Overview\nBelow is a diagram on how these concepts fit together.\n\n\n\n\nflowchart TB\n  %%styles\n  style JN fill:#FFA500\n  style FP fill:#cfe5ed\n  style SF fill:#dff1dd,stroke-dasharray: 5 5;\n  style QMD fill:#7286bb,color:#fff;\n  classDef files fill:#ede8ce ;\n  classDef code fill:#5695c7,color:#fff;\n  classDef container fill:#f9f9f6;\n  \n   %% list of nodes\n  FP(&lt;strong&gt;Processing Pipeline&lt;/strong&gt;\\ntransforms notebook based\\non directives and front-matter)\n  E(execnb)\n  SD(\"show_doc\")\n  SS(&lt;strong&gt;Static Site&lt;/strong&gt;\\nHTML, CSS and Javascript)\n  CF(\"Intermediate Output is stored in the &lt;code&gt;_procs/&lt;/code&gt; directory\\n\\n&lt;i&gt;(This is a full copy of your Quarto project)&lt;/i&gt;\")\n  class SD,E code;\n  \n  subgraph SF[\"&lt;strong&gt;Source Files&lt;/strong&gt;\"]\n      JN([Jupyter\\nNotebook])\n      QMD([\"Quarto\\nMarkdown\\n(.qmd)\"])\n  end\n  \n  \n  %% connections to things inside Notebook Processor (NBP)\n  JN -- json --&gt; FP\n  E -. \"cell execution\" .- SD\n  \n  subgraph NBP [\"&nbsp;&lt;strong&gt;Notebook Processor\\n&lt;/strong&gt;&nbsp;\"]\n      SD -.- |\"render API docs\"|FP\n  end\n  \n  FP -- modified json with only\\nQuarto directives remaining --&gt; CF\n  \n  subgraph Quarto [\"&nbsp;&lt;strong&gt;Quarto&lt;/strong&gt;\\n&nbsp;&lt;br&gt;\"]\n      direction LR\n      F[[_quarto.yml]] .-&gt; G[[custom.yml]] & H[[sidebar.yml]]\n      class F,G,H files;\n  end\n  \n  QMD --\"rendered\\ndirectly by Quarto\\n(no pre-processing required)\"--&gt; CF\n  CF --&gt; Quarto\n  Quarto --&gt; SS\n  \n  class NBP,CF,Quarto container;"
  },
  {
    "objectID": "contributing/docs.html#customizing-quarto",
    "href": "contributing/docs.html#customizing-quarto",
    "title": "Docs Website",
    "section": "Customizing Quarto",
    "text": "Customizing Quarto\nYou can create a custom.yml file in the same location as your _quarto.yml file to override any values in _quarto.yml. For example, assume your _quarto.yml file looks contains this:\n\nwebsite:\n  title: \"nbdev\"\n  site-url: \"https://nbdev.fast.ai/\"\n  description: \"Create delightful software with Jupyter Notebooks\"\n  twitter-card: true\n  open-graph: true\n  repo-branch: master\n  repo-url: \"https://github.com/fastai/nbdev\"\n  repo-actions: [issue]\n  navbar:\n    background: primary\n    search: true\n    right:\n      - icon: github\n        href: \"https://github.com/fastai/nbdev\"\n  sidebar:\n    style: \"floating\"\n\nLet’s assume you want to customize your sidebar navigation options such that instead of “floating” for sidebar.style, you wanted your navbar to be “docked”. Additionally, lets assume you want a different background color using the sidebar.background field which is not in the configuration above.\nTo accomplish these tasks, you would create a custom.yml in the same location as _quarto.yml with these contents:\n\nwebsite:\n  sidebar:\n      style: \"docked\"\n      background: \"dark\"\n\n\n\n\n\n\n\nNote\n\n\n\nYou can also set custom_quarto_yml = True in settings.ini if you wish to edit _quarto.yml directly instead of overriding settings in custom.yml.\n\n\n\nCustomizing The Sidebar\nBy default nbdev automatically generates sidebar.yml, which specifies the tree structure of your sidebar. nbdev infers the tree structure by inspecting the directory structure containing your source files. You can see an example of this by inspecting the folder structure of the notebooks directory in nbdev and the corresponding left-hand sidebar on this website. Leading numbers in filenames and directories are ignored when naming elements of the sidebar (which you can see examples of in this project’s notebooks directory).\nTo customize the sidebar, you must set custom_sidebar = true in settings.ini. This will prevent nbdev from regenerating this file every time the docs are re-built. This way, you an edit this file directly instead of overriding the sidebar with custom.yml."
  },
  {
    "objectID": "contributing/docs.html#how-show_doc-works",
    "href": "contributing/docs.html#how-show_doc-works",
    "title": "Docs Website",
    "section": "How show_doc works",
    "text": "How show_doc works\nWhen your documention website is built, all functions and classes you export to source code will be automatically documented with show_doc. This function outputs a summary of the symbol, showing its signature, docstring, and parameters. For instance, if you have this function:\n\ndef say_gday(\n    greeting:str=\"G'day\",  # Greeting to use\n    strine:bool=True,      # Use incomprehensible Aussie accent?\n    dropbears:bool=False): # Also warn about drop-bears?\n    \"Says g'day, the classic Aussie greeting\"\n    ...\n\nThis is how it’s rendered in the documentation, by automatically generating a temporary cell containing:\n\nshow_doc(say_gday)\n\n\nsay_gday\n\n say_gday (greeting:str=\"G'day\", strine:bool=True, dropbears:bool=False)\n\nSays g’day, the classic Aussie greeting\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ngreeting\nstr\nG’day\nGreeting to use\n\n\nstrine\nbool\nTrue\nUse incomprehensible Aussie accent?\n\n\ndropbears\nbool\nFalse\nAlso warn about drop-bears?\n\n\n\n\n\nBecause this is done automatically any time you build your docs (including automatically by continuous integration), your documentation will always contain current information about your code.\nYou can also document code that’s not created in a notebook, by using show_doc with imported code. For instance, if we wanted to document release_conda, we can import it and call show_doc(release_conda):\n\nfrom nbdev.release import release_conda\nshow_doc(release_conda)\n\nsource\n\nrelease_conda\n\n release_conda (path:str='conda', do_build:&lt;function bool_arg&gt;=True,\n                build_args:str='', skip_upload:&lt;function\n                store_true&gt;=False, mambabuild:&lt;function store_true&gt;=False,\n                upload_user:str=None)\n\nCreate a meta.yaml file ready to be built into a package, and optionally build and upload it\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npath\nstr\nconda\nPath where package will be created\n\n\ndo_build\nbool_arg\nTrue\nRun conda build step\n\n\nbuild_args\nstr\n\nAdditional args (as str) to send to conda build\n\n\nskip_upload\nstore_true\nFalse\nSkip anaconda upload step\n\n\nmambabuild\nstore_true\nFalse\nUse mambabuild (requires boa)\n\n\nupload_user\nstr\nNone\nOptional user to upload package to\n\n\n\n\n\n\nAutomatic Cell Execution\nWhen your documentation is built, all your manually added show_doc cells are run automatically. nbdev also executes all cells containing an import statement, and all exported cells – that way we can be sure that the symbol used in your show_doc cell is available.\nWe don’t, however, execute any other cells. That’s because you wouldn’t want to wait for your entire notebook to run just to build your docs; for instance, your docs might demonstrate training a model which takes hours to complete!\nThis leads to an important rule when authoring nbdev notebooks:\n\n\n\n\n\n\nWarning\n\n\n\nDo not mix import statements (or calls to show_doc) with other code in a single cell. If you do, all the code in that cell will be executed every time you build your docs, which might lead to errors (since not all previous cells will have been executed.\nInstead, put your imports in separate cells, and calls to show_doc should contain only that one line of code – the show_doc call.\n\n\nNote that nbdev automatically hides the actual show_doc(...) line of code. So your users only see the output.\n\nForcing Cells To Execute\nSometimes you may want to execute additional cells beyond what is automatically executed by nbdev. For instance, on our Getting Started page we show a list of all nbdev commands, automatically generated with nbdev_help. We want this page to always have the most up to date list of commands and docs, so we want it to always execute when the docs are rendered. To do that, add the following directive to the top of a cell:\n#| exec_doc\nAlternatively, you can get nbdev to automatically execute all cells when rendering your docs, by adding the following to your notebook frontmatter:\n---\nexec_all: true\n---\n\n\nSkipping Execution\nLikewise, you can instruct nbdev to not execute any cells when rendering your docs with the following front matter:\n---\nskip_showdoc: true\n---\nOr ignore execution for a specific cell with this directive:\n#|eval: false\n\n\n\nWhy use show_doc?\nMany Python developers use sphinx autodoc to automatically document a whole module all at once. Whilst this can work reasonably well, we think there are huge benefits for both developers and users in using nbdev’s approach instead\nThe premise of nbdev’s approach is that your documentation is important enough to be worth you taking the time to think carefully though each thing you want to show your users, what examples you’re going to provide, maybe adding some images to explain more complex ideas, and so forth. Jupyter provides a terrific environment for creating just these kinds of documents. For instance, with Jupyter you can:\n\nPaste images directly from your clipboard into a cell\nInsert code and have it executed and the results displayed to users\nCreate a hierarchy of headings to help structure your page\n…and much more.\n\nWith show_doc, you can insert automatically-updated API details for your library anywhere in a page. That means that you get to decide exactly how your page should look, and what information is provided where. You don’t have to limit yourself to the limits of ASCII art for diagrams, and can include full end-to-end code walk-through of the processes your users will be following."
  },
  {
    "objectID": "contributing/docs.html#previewing-your-site-locally",
    "href": "contributing/docs.html#previewing-your-site-locally",
    "title": "Docs Website",
    "section": "Previewing Your Site Locally",
    "text": "Previewing Your Site Locally\nYou can preview your docs anytime by running nbdev_preview. While in preview mode, you can make updates to notebooks and it will be reflected (after a small delay) in your browser."
  },
  {
    "objectID": "contributing/docs.html#deploying-docs-with-github-actions",
    "href": "contributing/docs.html#deploying-docs-with-github-actions",
    "title": "Docs Website",
    "section": "Deploying Docs With GitHub Actions",
    "text": "Deploying Docs With GitHub Actions\nIf your nbdev project lives in GitHub, we include automation that deploys your documentation site for you on GitHub Pages.\nnbdev comes bundled with a workflow file that enables this automation. This workflow is automatically triggered whenever you change any of the content in your repo. The following GitHub Actions workflows will run to generate a docs site (in this order):\n\nDeploy to GitHub Pages: This workflow builds the docs with nbdev. This is defined in deploy.yaml and references fastai/workflows/quarto-ghp.\npages build and deployment: This is an internal built-in workflow that GitHub provides whenever GitHub pages are enabled.\n\nShould anything go wrong in your page build, you can always look at the logs of these workflows. Like other workflows, these can be found in the Actions tab of your repo:\n\n\n\n\n\nTo read more about GitHub Actions, see their docs."
  },
  {
    "objectID": "contributing/docs.html#deploying-your-docs-on-other-platforms",
    "href": "contributing/docs.html#deploying-your-docs-on-other-platforms",
    "title": "Docs Website",
    "section": "Deploying Your Docs On Other Platforms",
    "text": "Deploying Your Docs On Other Platforms\nYou can generate all of the static assets for your site (html, css, etc) by running the command nbdev_docs. After running this command, all of the files for your documentation site will be located in the _docs/ directory (the location is configurable by doc_path in settings.ini) at the root of your repository. This directory is not checked into git and is ignored by .gitignore, but you can use these files to deploy to any hosting platform you want.\nYou can also use the quarto publish command to render your docs on a wide variety of other platforms, which is discussed in the Quarto docs here. After running the command nbdev_docs, the quarto publish command must be run from the root of the _proc/ directory, which is located at the root of your repo. The built-in help of quarto publish provides a good overview of the various targets available:\n\n\n\n\n\n\nCall nbdev_proc_nbs and publish from the _proc/ directory\n\n\n\nTo use quarto publish with nbdev, you must run the nbdev_proc_nbs command to pre-process your notebooks before publishing your docs. As a reminder, nbdev_proc_nbs creates the directory _proc/ at the root of your project that Quarto uses to render your site.\nFor example, to publish a site to Netlify you can run the following command from the root of your repo:\nnbdev_proc_nbs && cd _proc && quarto publish netlify\n\n\n\n!quarto publish -h\n\n\n  Usage:   quarto publish [provider] [path]\n  Version: 1.1.75                          \n                                           \n\n  Description:\n\n    Publish a document or project. Available providers include:\n                                                               \n     - Quarto Pub (quarto-pub)                                 \n     - GitHub Pages (gh-pages)                                 \n     - RStudio Connect (connect)                               \n                                                               \n     - Netlify (netlify)                                       \n    Accounts are configured interactively during publishing.   \n    Manage/remove accounts with: quarto publish accounts       \n\n  Options:\n\n    -h, --help              - Show this help.                                     \n    --id          &lt;id&gt;      - Identifier of content to publish                    \n    --server      &lt;server&gt;  - Server to publish to                                \n    --token       &lt;token&gt;   - Access token for publising provider                 \n    --no-render             - Do not render before publishing.                    \n    --no-prompt             - Do not prompt to confirm publishing destination     \n    --no-browser            - Do not open a browser to the site after publishing  \n    --log         &lt;level&gt;   - Path to log file                                    \n    --log-level   &lt;level&gt;   - Log level (info, warning, error, critical)          \n    --log-format  &lt;format&gt;  - Log format (plain, json-stream)                     \n    --quiet                 - Suppress console output.                            \n\n  Commands:\n\n    help  [command]  - Show this help or the help of a sub-command.\n\n  Examples:\n\n    Publish project (prompt for provider):  quarto publish                                                  \n    Publish document (prompt for provider): quarto publish document.qmd                                     \n    Publish project to Netlify:             quarto publish netlify                                          \n    Publish with explicit target:           quarto publish netlify --id DA36416-F950-4647-815C-01A24233E294 \n    Publish project to GitHub Pages:        quarto publish gh-pages                                         \n    Publish project to RStudio Connect:     quarto publish connect                                          \n    Publish with explicit credentials:      quarto publish connect --server example.com --token 01A24233E294\n    Publish without confirmation prompt:    quarto publish --no-prompt                                      \n    Publish without rendering:              quarto publish --no-render                                      \n    Publish without opening browser:        quarto publish --no-browser                                     \n    Manage/remove publishing accounts:      quarto publish accounts"
  },
  {
    "objectID": "explanations/index.html",
    "href": "explanations/index.html",
    "title": "Explanations",
    "section": "",
    "text": "These explanations provide background information on how nbdev is designed and how it works. They are designed to help people who want to more deeply understand the nbdev system.\n\n\n\n\n\n\n\n\n\n\nTitle\n\n\nDescription\n\n\n\n\n\n\nTemplate (for example)\n\n\nThe nbdev configuration file\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "UAV",
    "section": "",
    "text": "documentation is available at UAV docs"
  },
  {
    "objectID": "index.html#guide-to-developing-uav",
    "href": "index.html#guide-to-developing-uav",
    "title": "UAV",
    "section": "Guide to developing UAV",
    "text": "Guide to developing UAV\n\nInitial setup\nFor a step-by-step guide to using nbdev guide to using nbdev You’ll need the following software to develope using nbdev:\n\nPython venv\nA Python package manager: ie pip\nJupyter Notebook\n\npip install jupyter\n\nnbdev\n\npip install nbdev\n\nQuarto\n\nnbdev_install_quarto\n\nInstall Quarto JupyterLab extension\n\npip install jupyterlab-quarto\n\nInstall nbdev pre-commit hooks to catch and fix uncleaned and unexported notebooks\n\npip install pre-commit\nsee nbdev Pre-Commit Hooks for more details\n\n\nBuild the library\npip install UAV\n\n\nPreview Docs\nStart the preview by entering this into your terminal:\nnbdev_preview\n\n\nPrepare your changes\nBefore commiting your changes to GitHub we recommend running nbdev_prepare in the terminal,\nwhich bundles the following commands:\n\nnbdev_export: Builds the .py modules from Jupyter notebooks\nnbdev_test: Tests your notebooks\nnbdev_clean: Cleans your notebooks to get rid of extreanous output for git\nnbdev_readme: Updates your repo’s README.md file from your index notebook.\n\n\n\nUpdate Static site docs\nGenerate the static docs by entering nbdev_docs into your terminal:\n\n\nPush to GitHub\nYou can now commit and push your changes to GitHub. As we mentioned before, always remember to run nbdev_prepare before you commit to ensure your modules are exported and your tests pass. You can use git status to check which files have been generated or changed. Then:\ngit add .\ngit commit -m 'Add `say_hello`; update index' # Update this text with your own message\ngit push\nThis will kick-off your GitHub Actions. Wait a minute or two for those to complete, then check your updated repo and documentation."
  },
  {
    "objectID": "index.html#other",
    "href": "index.html#other",
    "title": "UAV",
    "section": "Other",
    "text": "Other\n\nSet up autoreload\nSince you’ll be often updating your modules from one notebook, and using them in another, it’s helpful if your notebook automatically reads in the new modules as soon as the Python file changes. To make this happen, just add these lines to the top of your notebook:\n%load_ext autoreload\n%autoreload 2"
  },
  {
    "objectID": "tutorials/api_walkthrough.html",
    "href": "tutorials/api_walkthrough.html",
    "title": "API Walkthrough",
    "section": "",
    "text": "The written tutorial below shows you how to create a Python package from scratch using nbdev.\nAlternatively, you can watch this video tutorial where Jeremy Howard and Hamel Husain guide you through a similar process step by step:"
  },
  {
    "objectID": "tutorials/api_walkthrough.html#installation",
    "href": "tutorials/api_walkthrough.html#installation",
    "title": "API Walkthrough",
    "section": "Installation",
    "text": "Installation\nYou’ll need the following software to complete the tutorial, read on for specific installation instructions:\n\nPython\nA Python package manager: we recommend conda or pip\nJupyter Notebook\nnbdev\nQuarto\n\nIf you haven’t worked with Python before, we recommend getting started with the Anaconda Individual Edition and using the conda package manager.\nNote that you will only need to follow the steps in the installation section once per environment. If you create a new repo, you won’t need to redo these.\n\nInstall JupyterLab\nLaunch a terminal and install JupyterLab by entering:\nconda install -c conda-forge -y jupyterlab\n…or\npip install jupyterlab\n…if you’re using the pip package manager.\nYou can now launch Jupyter by entering:\njupyter lab\nThis should open JupyterLab in a new browser tab:\n\n\n\n\n\n\n\nInstall nbdev\nThe next step is to install nbdev itself. JupyterLab comes with its own terminal, so we’ll use that moving forward.\nIn the Launcher, scroll down to the “Other” section, then click “Terminal”. If the Launcher isn’t opened, you can open it by clicking “File” → “New Launcher”.\nA new tab should open with a blank terminal – it might not look exactly the same, depending on how your shell is configured:\n\n\n\n\n\nFor Mac and Linux, enter:\nconda install -c fastai -y nbdev\n…or for Mac, Linux and Windows:\npip install nbdev\n…if you’re using pip.\n\n\nInstall Quarto\nnbdev provides a command to install the latest version of Quarto. In the terminal, enter:\nnbdev_install_quarto\nYour password may be requested at this point. Since nbdev is open source, you can read the source code of this command to verify that it isn’t doing anything malicious. Or, if you prefer, you may instead follow Quarto’s official installation instructions.\n\n\nInstall Quarto JupyterLab extension\nQuarto provides its own JupyterLab extension that allows it to render Quarto markdown content.\nFor example, here is their notebook demonstrating some of its features:\n\nInstall the extension by entering:\npip install jupyterlab-quarto\nNote that the jupyterlab-quarto package is not currently available via conda.\n\nYou’re all setup and ready to go! Installing these tools may take some time, but you’ll only need to do it once. Next, we’ll setup an nbdev repo for your specific project."
  },
  {
    "objectID": "tutorials/api_walkthrough.html#first-steps",
    "href": "tutorials/api_walkthrough.html#first-steps",
    "title": "API Walkthrough",
    "section": "First steps",
    "text": "First steps\nBy the end of this section you’ll have your own nbdev repo with tests, continuous integration, streamlined PyPI & conda packaging, and a documentation website.\n\nCreate an empty GitHub repo\nCreate an empty GitHub repo using the convenient link github.com/new. If you get stuck, you might find GitHub’s Create a repo page helpful.\nRemember to add a description, since nbdev will use that later. Don’t add a README file, .gitignore, or license just yet.\nIf you’re using the web interface, it should look something like this (with your own repository name and descrpition) before you click “Create Repository”:\n\n\n\n\n\nYou should then be redirected to your new repo:\n\n\n\n\n\n\n\n\n\n\n\nTry GitHub’s powerful CLI\n\n\n\n\n\nGitHub’s web interface is a great way to get started. As you grow more experienced, you might want to explore the GitHub CLI (command line interface). We often prefer to use command line tools for repetitive tasks where we’re likely to make mistakes. Having those tasks written as small scripts in your terminal means that you can repeat them with little effort.\n\n\n\n\n\nInitialise your repo with nbdev\nNow clone your repo from the Jupyter terminal you started earlier (or create a new terminal following those instructions if needed). If you get stuck here, you might find GitHub’s Cloning a repository page helpful.\nSince we created a repo named nbev-hello-world with the fastai user, we can clone it as follows:\ngit clone https://github.com/fastai/nbdev-hello-world.git\nThen cd (change directory) to our repo:\ncd nbdev-hello-world\nYou may have seen this message while cloning:\nYou appear to have cloned an empty repository.\n…since the repo is completely empty. Let’s add some files!\nnbdev provides the nbdev_new command to initialise an empty git repository. It’ll infer information about your project from git and GitHub, and ask you to input anything remaining. It will create files in your repo that:\n\nStreamline publishing Python packages to PyPI and conda.\nConfigure Quarto for publication-grade technical documentation.\nSetup GitHub actions to test notebooks and build and deploy Quarto docs to GitHub pages.\n\nInitialise your nbdev repo by entering:\nnbdev_new\nIt may ask you to enter information that it couldn’t infer from git or GitHub.\n\n\n\n\n\n\nNote\n\n\n\nnbdev_new assumes that your package name is the same as your repo name (with - replaced by _). Use the --lib_name option if that isn’t the case.\n\n\nDouble-check your settings.ini file to ensure that it has all of the correct information. Then commit and push your additions to GitHub:\ngit add .\ngit commit -m'Initial commit'\ngit push\n\n\nEnable GitHub Pages\nnbdev hosts your docs on GitHub Pages—an excellent (and free!) way to host websites.\n\n\n\n\n\n\nNote\n\n\n\nnbdev uses GitHub Pages by default because its easily accessible. However, you can use any host you like. See these docs for more information.\n\n\nYou need to enable GitHub Pages for your repo by clicking on the “Settings” tab near the top-right of your repo page, then “Pages” on the left, then setting the “Branch” to “gh-pages”, and finally clicking “Save”.\nIt should look similar to this after you click “Save”:\n\n\n\n\n\nNow it’s time to see all of the goodies nbdev gives you!\n\n\nCheck out your workflows\nOpen GitHub Actions by clicking the “Actions” tab near the top of your repo page. You should see two workflow runs:\n\n\n\n\n\nIf you opened this page shortly after pushing your initial commit, the runs may not have a green check (✅) because they’re still “In progress” or “Queued”. That’s no problem, they shouldn’t take much more than a minute to complete.\nIf you see a red cross (❌), that means something failed. Click on the cross, then click “Details”, and you’ll be able to see what failed. If you can’t figure out what’s wrong, search the forum in case someone else resolved the same issue, otherwise create a new post describing your issue in as much detail as you can, and we’ll try our best to help you. Remember that including a link to an actual repo and/or GitHub Action is the best way for us to quickly identify what’s wrong.\nWhat do these workflows do?\n\nCI – The CI (continuous integration) workflow streamlines your developer workflow, particularly with multiple collaborators. Every time you push to GitHub, it ensures that:\n\nYour notebooks and libraries are in sync\nYour notebooks are cleaned of unwanted metadata (which pollute pull requests and git histories and lead to merge conflicts)\nYour notebook tests all pass\n\nDeploy to GitHub Pages – Builds your docs with Quarto and deploys it to GitHub Pages.\n\nWe provide these basic workflows out-of-the-box, however, you can edit their corresponding YAML files in the .github/workflows/ folder to your liking.\n\n\nCheck out your docs\nWhen you enable GitHub Pages you should see a new workflow run: “pages build and deployment”. As the name suggests, this workflow deploys your website contents to GitHub Pages.\n\n\n\n\n\nWait for the workflow run to complete, then open your website. By default it should be available at: https://{user}.github.io/{repo}. For example, you can view fastai’s nbdev-hello-world docs at https://fastai.github.io/nbdev-hello-world.\n\n\n\n\n\n\n\nRecap\nYou now have a base nbdev repo with continuous integration and hosted documentation! Here’s a recap of the steps you took:\n\nCreated a GitHub repo (with GitHub Pages enabled)\nInitialised your repo with nbdev_new\nPushed to GitHub."
  },
  {
    "objectID": "tutorials/api_walkthrough.html#make-your-first-edit",
    "href": "tutorials/api_walkthrough.html#make-your-first-edit",
    "title": "API Walkthrough",
    "section": "Make your first edit",
    "text": "Make your first edit\nIn this section, you’ll make your first edit to the repo you created in First steps.\n\nInstall hooks for git-friendly notebooks\nStep one when working with Jupyter notebooks in a new repo is to install nbdev’s hooks (you can think of “hooks” as plugins or extensions to an application).\nInstall them by entering this command in your terminal:\nnbdev_install_hooks\n\n\n\n\n\n\nNote\n\n\n\nThe clean hook currently only supports Jupyter Notebook and JupyterLab. If you’re using VSCode, you can try the experimental nbdev VSCode extension. Otherwise, you might also want to try nbdev’s pre-commit hooks.\n\n\nSee Git-friendly Jupyter for more about how nbdev hooks work and how to customise them. Here’s a short summary:\n\nFix broken notebooks due to git merge conflicts so that they can be opened and resolved directly in Jupyter.\nEach time you save a Jupyter notebook, automatically clean unwanted metadata to remove unnecessary changes in pull requests and reduce the chance of git merge conflicts.\nAutomatically trust notebooks in the repo so that you can view widgets from collaborators’ commits. For this reason, you should not install hooks into a repo you don’t trust.\n\n\n\n\n\n\n\nTip\n\n\n\nnbdev’s git hooks work on any git repo, even if it doesn’t use the broader nbdev system.\n\n\n\n\nBuild your library\nYou should now create your package from your notebook by running:\nnbdev_export\nThis will create Python modules for your notebooks. These modules will make up the contents of your Python package.\n\n\nInstall your package\nYou might have noticed that nbdev_new created a Python package in your repo. In our case, it was automatically named nbdev_hello_world by using our repo name nbdev-hello-world and replacing - with _ to make it a valid Python package.\nThe next step is to install your package by entering this into your terminal:\npip install -e '.[dev]'\nThis is the recommended way to make a Python package importable from anywhere in your current environment:\n\n-e – short for “editable”, lets you immediately use changes made to your package without having to reinstall, which is convenient for development.\n. – refers to the current directory.\n[dev] – includes “development” requirements: other packages that your notebooks use solely for documentation or testing.\n\n\n\nPreview your docs\nnbdev is an interactive programming environment that values fast feedback loops. The nbdev_preview command helps achieve this by using Quarto to render your docs on your computer and keep them updated as your edit your notebooks.\nStart the preview by entering this into your terminal:\nnbdev_preview\nIt may say Preparing to preview for a few seconds while it gets started, and will eventually display something like:\nWatching files for changes\nBrowse at http://localhost:3000/\nClick the link to open the preview in a new browser tab. It should look exactly like your online docs.\n\n\n\n\n\n\nTip\n\n\n\nWe often find it useful to keep a preview window open on the side while we’re editing our notebooks in Jupyter.\n\n\n\n\nEdit 00_core.ipynb\nNow, open the nbs/00_core.ipynb file (generated by running nbdev_new earlier) in Jupyter. You don’t have to start your notebook names with a number, but we find it helpful to show the order that your project should be read in – even though it could have been created in a different order.\n\nAdd your own frontmatter\nYou’ll see something that looks a bit like this:\n\ncore\n\nFill in a module description here\n\n#| default_exp core\n\nLet’s explain what these special cells means:\n\nThe first is a markdown cell with nbdev’s markdown frontmatter syntax that defines notebook metadata used by Quarto, our documentation engine (see the frontmatter reference page for more). It contains:\n\nH1 header (“core”) – defining the page title\nQuote (“Fill in a module description here”) – defining the page description\n\nThe second is a code cell with a directive default_exp which decides which module this notebook will export to (see the Directives explanation for more). Currently, it exports to the core module.\n\nNext, rename the notebook, replace the title and description, and change the default export module for your own project.\nOnce you’re done, save the notebook. The live preview started in the previous section should update with your latest changes.\nRerun all cells in your notebook to ensure that they work, and to export the updated modules.\n\n\n\n\n\n\nTip\n\n\n\nWe find the “restart kernel and run all cells” Jupyter command (the ⏩ button) so invaluable that we bind it to a keyboard shortcut. A common criticism of notebooks is that out-of-order execution leads to irreproducible notebooks. In our experience, making “restart and rerun” a habit solves this problem.\n\n\nRunning the notebook exports Python modules because of the last cell which contains:\n#| hide\nimport nbdev; nbdev.nbdev_export()\nWhat does this mean?\n\n#| hide is a directive (like #| default_exp) which excludes a cell from both your exported module and docs\nnbdev_export is the command used to export your notebooks to Python modules.\n\nWe recommend including a cell like this at the bottom of all of the notebooks you want to export.\n\n\n\n\n\n\nWarning\n\n\n\nRemember to delete any unused modules that aren’t exported by a notebook or otherwise needed by your package. This is likely to happen if you change the default export of a notebook – nbdev doesn’t remove the old module. This is intended, since nbdev is designed to work with hybrid packages that use .py modules (with no corresponding notebook) as well as those exported from notebooks.\n\n\n\n\nAdd your own function\nAdd a new code cell below the #| default_exp cell with a function. For example:\n#| export\ndef say_hello(to):\n    \"Say hello to somebody\"\n    return f'Hello {to}!'\nNotice how it includes #| export at the top – this is a directive (like #| default_exp) that tells nbdev to include the cell in your exported module and in your documentation.\nThe documentation should look like this:\n\n\n\nsay_hello\n\n say_hello (to)\n\nSay hello to somebody\n\n\n\n\nAdd your own examples, tests, and docs\nOne of the superpowers of notebook-driven development is that you can very easily add examples, tests, and documentation right below your code.\nInclude regular code cells, and they’ll appear (with output) in your docs, for example:\n\nsay_hello(\"Isaac\")\n\n'Hello Isaac!'\n\n\nThis is a test too! When you run nbdev_test it will execute this cell (and all other test cells) and fail if they raise any exceptions.\nFor tests, it’s preferred to use more explicit asserts:\n\nassert say_hello(\"Hamel\") == \"Hello Hamel!\"\n\n…or functions from fastcore.test, which behave like assert but also display the actual and expected values if they differ:\n\nfrom fastcore.test import *\n\n\ntest_eq(say_hello(\"Hamel\"), \"Hello Hamel!\")\n\nAnother superpower of notebook-driven development is that your examples can include plots, images, and even JavaScript widgets. For example, here’s an SVG circle:\n\nfrom IPython.display import display,SVG\n\n\ndisplay(SVG('&lt;svg height=\"100\" xmlns=\"http://www.w3.org/2000/svg\"&gt;&lt;circle cx=\"50\" cy=\"50\" r=\"40\"/&gt;&lt;/svg&gt;'))\n\n\n\n\n\n\n\nPrepare your changes\nBefore commiting your changes to GitHub we recommend running nbdev_prepare in the terminal, which bundles the following commands:\n\nnbdev_export: Builds the .py modules from Jupyter notebooks\nnbdev_test: Tests your notebooks\nnbdev_clean: Cleans your notebooks to get rid of extreanous output for git\nnbdev_readme: Updates your repo’s README.md file from your index notebook.\n\n\n\nEdit index.ipynb\nNow you’re ready to personalize your documentation home page and README.md file; these are both generated automatically from index.ipynb. Open Jupyter, then click on nbs/index.ipynb to open it.\nWe recommend including a longer description about what your package does, how to install it, and how to use it (with a few examples which import and use your package). Remember, examples can be code cells with real outputs rather than plain markdown text – they’ll double as tests too!\n\n\nPush to Github\nYou can now commit and push your changes to GitHub. As we mentioned before, always remember to run nbdev_prepare before you commit to ensure your modules are exported and your tests pass. You can use git status to check which files have been generated or changed. Then:\ngit add .\ngit commit -m 'Add `say_hello`; update index' # Update this text with your own message\ngit push\nThis will kick-off your GitHub Actions. Wait a minute or two for those to complete, then check your updated repo and documentation.\n\n\nRecap\nCongratulations, you’ve used all of the basics needed to build delightful projects with nbdev! Here’s a recap of the steps you took:\n\nInstalled hooks for git-friendly notebooks with nbdev_install_hooks\nInstalled your package with pip install -e '.[dev]'\nPreviewed your docs with nbdev_preview\nAdded your own frontmatter, function, tests, and docs to nbs/00_core.ipynb\nPrepared your changes with nbdev_prepare\nUpdated nbs/index.ipynb with your own information\nPushed to GitHub.\n\nRead on to learn about more advanced nbdev functionality. Also see our explanations for deep-dives on specific topics, as well as our other tutorials."
  },
  {
    "objectID": "tutorials/api_walkthrough.html#advanced-functionality",
    "href": "tutorials/api_walkthrough.html#advanced-functionality",
    "title": "API Walkthrough",
    "section": "Advanced functionality",
    "text": "Advanced functionality\n\nAdd a class\nCreate a class in 00_core.ipynb as follows:\n#| export\nclass HelloSayer:\n    \"Say hello to `to` using `say_hello`\"\n    def __init__(self, to): self.to = to\n        \n    def say(self):\n        \"Do the saying\"\n        return say_hello(self.to)\nThis will automatically appear in the docs like this:\n\n\n\nHelloSayer\n\n HelloSayer (to)\n\nSay hello to to using say_hello\n\nDocument with show_doc\nHowever, methods aren’t automatically documented. To add method docs, use show_doc:\nshow_doc(HelloSayer.say)\n\n\n\n\nHelloSayer.say\n\n HelloSayer.say ()\n\nDo the saying\nAnd add some examples and/or tests:\n\no = HelloSayer(\"Alexis\")\no.say()\n\n'Hello Alexis!'\n\n\n\n\nAdd links with backticks\nNotice above there is a link from our new class documentation to our function. That’s because we used backticks in the docstring:\n    \"Say hello to `to` using `say_hello`\"\nThese are automatically converted to hyperlinks wherever possible. For instance, here are hyperlinks to HelloSayer and say_hello created using backticks.\n\n\nSet up autoreload\nSince you’ll be often updating your modules from one notebook, and using them in another, it’s helpful if your notebook automatically reads in the new modules as soon as the Python file changes. To make this happen, just add these lines to the top of your notebook:\n%load_ext autoreload\n%autoreload 2\n\n\nSet up prerequisites\nIf your module requires other modules as dependencies, you can add those prerequisites to your settings.ini in the requirements section. The requirements should be separated by a space and if the module requires at least or at most a specific version of the requirement this may be specified here, too.\nFor example if your module requires the fastcore module of at least version 1.0.5, the torchvision module of at most version 0.7 and any version of matplotlib, then the prerequisites would look like this:\nrequirements = fastcore&gt;=1.0.5 torchvision&lt;0.7 matplotlib\nIn addition to requirements you can specify dependencies with other keywords that have different scopes. Below is a list of all possible dependency keywords:\n\nrequirements: Passed to both pip and conda setup\npip_requirements: Passed to pip setup only\nconda_requirements: Passed to conda setup only\ndev_requirements: Passed to pip setup as a development requirement\n\nFor more information about the format of dependencies, see the pypi and conda docs on creating specifications in setup.py and meta.yaml, respectively.\n\n\nSet up console scripts\nBehind the scenes, nbdev uses that standard package setuptools for handling installation of modules. One very useful feature of setuptools is that it can automatically create cross-platform console scripts. nbdev surfaces this functionality; to use it, use the same format as setuptools, with whitespace between each script definition (if you have more than one).\nconsole_scripts = nbdev_export=nbdev.cli:nbdev_export\n\n\nUpload to pypi\nIf you want people to be able to install your project by just typing pip install your-project then you need to upload it to pypi. The good news is, we’ve already created a fully pypi compliant installer for your project! So all you need to do is register at pypi (click “Register” on pypi) if you haven’t previously done so, and then create a file called ~/.pypirc with your login details. It should have these contents:\n[pypi]\nusername = your_pypi_username\npassword = your_pypi_password\nAnother thing you will need is twine, so you should run once\npip install twine\nTo upload your project to pypi, just type nbdev_pypi in your project root directory. Once it’s complete, a link to your project on pypi is displayed.\n\n\nUpload to conda\nSimilar to pip install support, we have provided an anaconda compliant installer to upload your project to anaconda. Once uploaded, your package can be installed by typing conda install -c your_anaconda_username your-project.\nYou need to register at anaconda (fill out the form to Sign Up) which will create a username and password. You will then need to install the following packages\npip install anaconda-client conda-build conda-verify\nBefore running the anaconda uploader, you need to login to conda using the CLI command (you will be prompted to enter your username and password)\nanaconda login\nTo upload to anaconda, just type nbdev_conda in your project root directory.\n\n\nUpload to pypi and conda\nThe command nbdev_release_both from the root of your nbdev repo will upload your project to both conda and pypi.\n\n\nInstall collapsible headings and toc2\nThere are two jupyter notebook extensions that I highly recommend when working with projects like this. They are:\n\nCollapsible headings: This lets you fold and unfold each section in your notebook, based on its markdown headings. You can also hit left to go to the start of a section, and right to go to the end\nTOC2: This adds a table of contents to your notebooks, which you can navigate either with the Navigate menu item it adds to your notebooks, or the TOC sidebar it adds. These can be modified and/or hidden using its settings.\n\n\n\nMath equation support\nnbdev supports equations (using Quarto). You can include math in your notebook’s documentation using the following methods.\nUsing $$, e.g.:\n$$\\sum_{i=1}^{k+1}i$$\nWhich is rendered as:\n\n\\[\\sum_{i=1}^{k+1}i\\]\n\nUsing $, e.g.:\nThis version is displayed inline: $\\sum_{i=1}^{k+1}i$ . You can include text before and after.\nWhich is rendered as:\n\nThis version is displayed inline: \\(\\sum_{i=1}^{k+1}i\\) . You can include text before and after.\n\nFor more information, see the Quarto Docs\n\n\nLook at nbdev “source” for more ideas\nDon’t forget that nbdev itself is written in nbdev! It’s a good place to look to see how fast.ai uses it in practice, and get a few tips. You’ll find the nbdev notebooks here in the nbs folder on Github.\n\n\nQuarto Features\nnbdev supports most Quarto features. We encourage you to read the Quarto documentation to discover all the features available to you. For example, this is how you can incorporate mermaid charts:\n\n\n\n\nflowchart LR\n  A[Hard edge] --&gt; B(Round edge)\n  B --&gt; C{Decision}\n  C --&gt; D[Result one]\n  C --&gt; E[Result two]\n\n\n\n\n\nHere is another example of using Graphviz:\n\n\n\n\n\n\n\nG\n\n  \n\nrun\n\n run   \n\nintr\n\n intr   \n\nrun–intr\n\n   \n\nkernel\n\n kernel   \n\nrun–kernel\n\n   \n\nrunbl\n\n runbl   \n\nintr–runbl\n\n   \n\nrunbl–run\n\n   \n\nzombie\n\n zombie   \n\nkernel–zombie\n\n   \n\nsleep\n\n sleep   \n\nkernel–sleep\n\n   \n\nrunmem\n\n runmem   \n\nkernel–runmem\n\n   \n\nsleep–runmem\n\n   \n\nswap\n\n swap   \n\nsleep–swap\n\n   \n\nrunswap\n\n runswap   \n\nswap–runswap\n\n   \n\nrunswap–runmem\n\n   \n\nnew\n\n new   \n\nrunswap–new\n\n   \n\nnew–runmem\n\n  \n\n\n\n\n\nIt is worth taking a look at the documentation for figures, callouts, markdown, widgets, layouts, conditional content and quarto extensions to name a few useful things we have encountered."
  }
]