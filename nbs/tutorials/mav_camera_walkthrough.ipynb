{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mavlink Camera Walkthrough\n",
    ">  Documentation \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# skip_showdoc: true to avoid running cells when rendering docs, and skip_exec: true to skip this notebook when running tests. \n",
    "# this should be a raw cell "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "skip_showdoc: true\n",
    "skip_exec: true\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Camera Manager\n",
    "> Here we create an entire mavlink connection with client at the GCS and server at the camera. The client and server are connected via a UDP connection or a radio modem serial connection\n",
    "> The camera can be controlled via the client, and the video stream is sent from the server to the client. The client can also request camera information, storage information, etc from the server.\n",
    "> The operatrion of the two cameras is controlled from a gui, which allows streaming , jpeg snapshots and recodring to be controlled\n",
    "![](images/cam_man_gui.png){fig-align=\"center\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found config directory at: /home/john/PycharmProjects/UAV/config\n",
      "cv2_display udpsrc port={} ! application/x-rtp, media=(string)video, clock-rate=(int)90000, encoding-name=(string)H264, payload=(int)96 ! queue ! rtph264depay ! avdec_h264 ! videoconvert ! capsfilter caps=video/x-raw,format=BGR  ! appsink name=mysink emit-signals=true  sync=false \n",
      "boot_time_str ='2024-01-24|10:21:20'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO |40.293| pygst.GstVideoS | gst_tools.:225 | MainThread | Process-2  | Starting GstVideoSource: udpsrc port=5000 ! application/x-rtp, media=(string)video, clock-rate=(int)90000, encoding-name=(string)H264, payload=(int)96 ! queue ! rtph264depay ! avdec_h264 ! videoconvert ! capsfilter caps=video/x-raw,format=BGR  ! appsink name=mysink emit-signals=true  sync=false \u001b[0m\n",
      "\u001b[37mDEBUG|40.294| pygst.GstVideoS | gst_tools.:229 | MainThread | Process-2  | GstVideoSource Setting pipeline state to PLAYING ... \u001b[0m\n",
      "\u001b[37mDEBUG|40.295| pygst.GstVideoS | gst_tools.:231 | MainThread | Process-2  | GstVideoSource Pipeline state set to PLAYING \u001b[0m\n",
      "\u001b[32mINFO |40.298| pygst.GstVideoS | gst_tools.:225 | MainThread | Process-2  | Starting GstVideoSource: udpsrc port=5001 ! application/x-rtp, media=(string)video, clock-rate=(int)90000, encoding-name=(string)H264, payload=(int)96 ! queue ! rtph264depay ! avdec_h264 ! videoconvert ! capsfilter caps=video/x-raw,format=BGR  ! appsink name=mysink emit-signals=true  sync=false \u001b[0m\n",
      "\u001b[37mDEBUG|40.299| pygst.GstVideoS | gst_tools.:229 | MainThread | Process-2  | GstVideoSource Setting pipeline state to PLAYING ... \u001b[0m\n",
      "\u001b[37mDEBUG|40.299| pygst.GstVideoS | gst_tools.:231 | MainThread | Process-2  | GstVideoSource Pipeline state set to PLAYING \u001b[0m\n",
      "\u001b[32mINFO |40.359| mavcom.CameraCl | basecompon:123 | MainThread | MainProces | Component Started self.source_component = 11, self.mav_type = 6, self.source_system = 111\u001b[0m\n",
      "\u001b[32mINFO |40.361| uav.GSTCamera   | gst_cam.py:354 | MainThread | MainProces | GSTCamera Started\u001b[0m\n",
      "\u001b[32mINFO |40.361| uav.GSTCamera   | gst_cam.py:580 | MainThread | MainProces | Setting camera_UDP_IP = 127.0.0.1\u001b[0m\n",
      "\u001b[32mINFO |40.362| uav.GSTCamera   | gst_cam.py:580 | MainThread | MainProces | Setting cam_0_UDP_port = 5000\u001b[0m\n",
      "\u001b[32mINFO |40.374| pygst.GstPipeli | gst_tools.:225 | MainThread | MainProces | Starting GstPipeline: videotestsrc pattern=ball is-live=true ! timeoverlay ! textoverlay text=\"Front\" valignment=top halignment=right font-desc=\"Sans, 18\" shaded-background=true ! capsfilter caps=video/x-raw,format=RGB,width=800,height=600,framerate=30/1 ! tee name=t t. ! queue ! videoscale  ! capsfilter caps=video/x-raw,format=RGB,width=400,height=300 ! videoconvert ! autovideosink t. ! interpipesink name=cam_0 \u001b[0m\n",
      "\u001b[37mDEBUG|40.375| pygst.GstPipeli | gst_tools.:229 | MainThread | MainProces | GstPipeline Setting pipeline state to PLAYING ... \u001b[0m\n",
      "\u001b[37mDEBUG|40.375| pygst.GstPipeli | gst_tools.:231 | MainThread | MainProces | GstPipeline Pipeline state set to PLAYING \u001b[0m\n",
      "\u001b[32mINFO |40.377| pygst.GstStream | gst_tools.:225 | MainThread | MainProces | Starting GstStreamUDP: interpipesrc listen-to=cam_0 is-live=true allow-renegotiation=true format=time ! valve name=myvalve drop=False  ! queue ! videorate drop-only=true skip-to-first=true ! video/x-raw,framerate=2/1 ! videoconvert ! x264enc tune=zerolatency noise-reduction=10000 bitrate=2048 speed-preset=superfast ! rtph264pay ! udpsink host=127.0.0.1 port=5000 sync=true\u001b[0m\n",
      "\u001b[37mDEBUG|40.377| pygst.GstStream | gst_tools.:229 | MainThread | MainProces | GstStreamUDP Setting pipeline state to PLAYING ... \u001b[0m\n",
      "\u001b[37mDEBUG|40.378| pygst.GstStream | gst_tools.:231 | MainThread | MainProces | GstStreamUDP Pipeline state set to PLAYING \u001b[0m\n",
      "\u001b[32mINFO |40.379| uav.GSTCamera   | gst_cam.py:748 | MainThread | MainProces | Video streaming pipeline \"gstreamer_udpsink\" created on port 5000\u001b[0m\n",
      "\u001b[37mDEBUG|40.479| pygst.GstStream | gst_tools.:265 | MainThread | MainProces | Valve \"myvalve\" state set to True\u001b[0m\n",
      "\u001b[32mINFO |40.480| uav.GSTCamera   | gst_cam.py:764 | MainThread | MainProces | Video streaming \"gstreamer_udpsink\" stopped (paused) on port 5000\u001b[0m\n",
      "\u001b[32mINFO |40.482| uav.GSTCamera   | gst_cam.py:354 | MainThread | MainProces | GSTCamera Started\u001b[0m\n",
      "\u001b[32mINFO |40.483| uav.GSTCamera   | gst_cam.py:580 | MainThread | MainProces | Setting camera_UDP_IP = 127.0.0.1\u001b[0m\n",
      "\u001b[32mINFO |40.483| uav.GSTCamera   | gst_cam.py:580 | MainThread | MainProces | Setting cam_1_UDP_port = 5001\u001b[0m\n",
      "\u001b[32mINFO |40.497| pygst.GstPipeli | gst_tools.:225 | MainThread | MainProces | Starting GstPipeline: videotestsrc pattern=ball is-live=true ! timeoverlay ! textoverlay text=\"Left\" valignment=top halignment=right font-desc=\"Sans, 18\" shaded-background=true ! capsfilter caps=video/x-raw,format=RGB,width=800,height=600,framerate=30/1 ! tee name=t t. ! queue ! videoscale  ! capsfilter caps=video/x-raw,format=RGB,width=400,height=300 ! videoconvert ! autovideosink t. ! interpipesink name=cam_1 \u001b[0m\n",
      "\u001b[37mDEBUG|40.498| pygst.GstPipeli | gst_tools.:229 | MainThread | MainProces | GstPipeline Setting pipeline state to PLAYING ... \u001b[0m\n",
      "\u001b[37mDEBUG|40.498| pygst.GstPipeli | gst_tools.:231 | MainThread | MainProces | GstPipeline Pipeline state set to PLAYING \u001b[0m\n",
      "\u001b[32mINFO |40.500| pygst.GstStream | gst_tools.:225 | MainThread | MainProces | Starting GstStreamUDP: interpipesrc listen-to=cam_1 is-live=true allow-renegotiation=true format=time ! valve name=myvalve drop=False  ! queue ! videorate drop-only=true skip-to-first=true ! video/x-raw,framerate=2/1 ! videoconvert ! x264enc tune=zerolatency noise-reduction=10000 bitrate=2048 speed-preset=superfast ! rtph264pay ! udpsink host=127.0.0.1 port=5001 sync=true\u001b[0m\n",
      "\u001b[37mDEBUG|40.500| pygst.GstStream | gst_tools.:229 | MainThread | MainProces | GstStreamUDP Setting pipeline state to PLAYING ... \u001b[0m\n",
      "\u001b[37mDEBUG|40.501| pygst.GstStream | gst_tools.:231 | MainThread | MainProces | GstStreamUDP Pipeline state set to PLAYING \u001b[0m\n",
      "\u001b[32mINFO |40.502| uav.GSTCamera   | gst_cam.py:748 | MainThread | MainProces | Video streaming pipeline \"gstreamer_udpsink\" created on port 5001\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found config directory at: /home/john/PycharmProjects/UAV/config\n",
      "{'source_system': 222, 'camera_UDP_IP': '127.0.0.1', 'cam_0_UDP_port': 5000, 'cam_1_UDP_port': 5001, 'cam_10_UDP_port': 5010, 'usb_mount_command': 'udisksctl mount -b /dev/sda', 'image_save_path': '/media/{user}/jpgs', 'mavlink': {'source_system': 222, 'connection': '/dev/ttyUSB1'}}\n",
      "Found config directory at: /home/john/PycharmProjects/UAV/config\n",
      "John Doe                        \n",
      "Found config directory at: /home/john/PycharmProjects/UAV/config\n",
      "John Doe                        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37mDEBUG|40.602| pygst.GstStream | gst_tools.:265 | MainThread | MainProces | Valve \"myvalve\" state set to True\u001b[0m\n",
      "\u001b[32mINFO |40.603| uav.GSTCamera   | gst_cam.py:764 | MainThread | MainProces | Video streaming \"gstreamer_udpsink\" stopped (paused) on port 5001\u001b[0m\n",
      "\u001b[32mINFO |40.604| mavcom.CameraSe | basecompon:123 | MainThread | MainProces | Component Started self.source_component = 100, self.mav_type = 30, self.source_system = 222\u001b[0m\n",
      "\u001b[32mINFO |40.605| mavcom.CameraSe | basecompon:123 | MainThread | MainProces | Component Started self.source_component = 101, self.mav_type = 30, self.source_system = 222\u001b[0m\n",
      "\u001b[33mWARNI|40.606| root            | asyncio_gu:271 | MainThread | MainProces | Gui auto is not callable\u001b[0m\n",
      "\u001b[33mWARNI|40.607| root            | asyncio_gu:273 | MainThread | MainProces | Gui reset is not callable\u001b[0m\n",
      "\u001b[33mWARNI|40.607| root            | asyncio_gu:275 | MainThread | MainProces | Gui pause is not callable\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera Heartbeat ret = (222, 100)\n",
      "find_gimbals exit_event =  <asyncio.locks.Event object at 0x7f6fe1d06200 [unset]>\n",
      " Found Camera 222/101\n",
      " Found Camera 222/100\n",
      "run_gui exit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37mDEBUG|43.667| pygst.GstPipeli | gst_tools.:294 | MainThread | MainProces | GstPipeline Stopping pipeline ...\u001b[0m\n",
      "\u001b[37mDEBUG|43.669| pygst.GstPipeli | gst_tools.:298 | MainThread | MainProces | GstPipeline Sending EOS event ...\u001b[0m\n",
      "\u001b[37mDEBUG|43.771| pygst.GstPipeli | gst_tools.:315 | MainThread | MainProces | GstPipeline Reseting pipeline state ....\u001b[0m\n",
      "\u001b[37mDEBUG|43.814| pygst.GstPipeli | gst_tools.:322 | MainThread | MainProces | GstPipeline Gst.Pipeline successfully destroyed\u001b[0m\n",
      "\u001b[32mINFO |43.815| pygst.GstPipeli | gst_tools.:335 | MainThread | MainProces | GstPipeline Shutdown\u001b[0m\n",
      "\u001b[32mINFO |43.817| uav.GSTCamera   | gst_cam.py:516 | MainThread | MainProces | GSTCamera closed\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find_cameras exit True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37mDEBUG|43.987| pygst.GstStream | gst_tools.:967 | Thread-22  | MainProces | Sending EOS event, to trigger shutdown of pipeline\u001b[0m\n",
      "\u001b[32mINFO |43.989| pygst.GstStream | gst_tools.:335 | MainThread | MainProces | GstStreamUDP Shutdown\u001b[0m\n",
      "\u001b[32mINFO |43.990| uav.GSTCamera   | gst_cam.py:803 | MainThread | MainProces | !!!!!! Closed \"gstreamer_udpsink\" \u001b[0m\n",
      "\u001b[37mDEBUG|43.991| pygst.GstPipeli | gst_tools.:294 | MainThread | MainProces | GstPipeline Stopping pipeline ...\u001b[0m\n",
      "\u001b[37mDEBUG|43.992| pygst.GstPipeli | gst_tools.:298 | MainThread | MainProces | GstPipeline Sending EOS event ...\u001b[0m\n",
      "\u001b[37mDEBUG|44.094| pygst.GstPipeli | gst_tools.:315 | MainThread | MainProces | GstPipeline Reseting pipeline state ....\u001b[0m\n",
      "\u001b[37mDEBUG|44.110| pygst.GstPipeli | gst_tools.:322 | MainThread | MainProces | GstPipeline Gst.Pipeline successfully destroyed\u001b[0m\n",
      "\u001b[32mINFO |44.111| pygst.GstPipeli | gst_tools.:335 | MainThread | MainProces | GstPipeline Shutdown\u001b[0m\n",
      "\u001b[32mINFO |44.112| uav.GSTCamera   | gst_cam.py:516 | MainThread | MainProces | GSTCamera closed\u001b[0m\n",
      "\u001b[37mDEBUG|44.309| pygst.GstStream | gst_tools.:967 | Thread-23  | MainProces | Sending EOS event, to trigger shutdown of pipeline\u001b[0m\n",
      "\u001b[32mINFO |44.311| pygst.GstStream | gst_tools.:335 | MainThread | MainProces | GstStreamUDP Shutdown\u001b[0m\n",
      "\u001b[32mINFO |44.312| uav.GSTCamera   | gst_cam.py:803 | MainThread | MainProces | !!!!!! Closed \"gstreamer_udpsink\" \u001b[0m\n",
      "\u001b[32mINFO |44.363| pygst.GstPipeli | gst_tools.:335 | MainThread | MainProces | GstPipeline Shutdown\u001b[0m\n",
      "\u001b[32mINFO |44.364| uav.GSTCamera   | gst_cam.py:516 | MainThread | MainProces | GSTCamera closed\u001b[0m\n",
      "\u001b[32mINFO |44.465| pygst.GstStream | gst_tools.:335 | MainThread | MainProces | GstStreamUDP Shutdown\u001b[0m\n",
      "\u001b[32mINFO |44.466| uav.GSTCamera   | gst_cam.py:803 | MainThread | MainProces | !!!!!! Closed \"gstreamer_udpsink\" \u001b[0m\n",
      "\u001b[32mINFO |44.467| mavcom.CameraSe | basecompon:417 | MainThread | MainProces | CameraServer closed (not waiting for _t_heartbeat daemon thread)\u001b[0m\n",
      "\u001b[32mINFO |44.469| pygst.GstPipeli | gst_tools.:335 | MainThread | MainProces | GstPipeline Shutdown\u001b[0m\n",
      "\u001b[32mINFO |44.470| uav.GSTCamera   | gst_cam.py:516 | MainThread | MainProces | GSTCamera closed\u001b[0m\n",
      "\u001b[32mINFO |44.571| pygst.GstStream | gst_tools.:335 | MainThread | MainProces | GstStreamUDP Shutdown\u001b[0m\n",
      "\u001b[32mINFO |44.573| uav.GSTCamera   | gst_cam.py:803 | MainThread | MainProces | !!!!!! Closed \"gstreamer_udpsink\" \u001b[0m\n",
      "\u001b[32mINFO |44.574| mavcom.CameraSe | basecompon:417 | MainThread | MainProces | CameraServer closed (not waiting for _t_heartbeat daemon thread)\u001b[0m\n",
      "\u001b[32mINFO |44.611| mavcom.CameraCl | basecompon:417 | MainThread | MainProces | CameraClient closed (not waiting for _t_heartbeat daemon thread)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%autoawait asyncio\n",
    "import asyncio\n",
    "import platform\n",
    "\n",
    "from UAV.cameras.gst_cam import GSTCamera\n",
    "from UAV.logging import LogLevels\n",
    "from UAV.manager import Gui\n",
    "from UAV.mavlink import CameraClient, CameraServer, MAVCom, mavlink, GimbalServerViewsheen\n",
    "\n",
    "from UAV.utils import helpers\n",
    "from UAV.utils.general import boot_time_str, toml_load, config_dir\n",
    "\n",
    "\n",
    "# gst_utils.set_gst_debug_level(Gst.DebugLevel.FIXME)\n",
    "\n",
    "async def main():\n",
    "    con1, con2 = \"udpin:localhost:14445\", \"udpout:localhost:14445\"\n",
    "    # con1, con2 = \"/dev/ttyACM0\", \"/dev/ttyUSB1\"\n",
    "    # con1, con2 = \"/dev/ttyACM0\", \"/dev/ttyACM2\"\n",
    "    # logger.disabled = True\n",
    "    print(f\"{boot_time_str =}\")\n",
    "\n",
    "    # with GstContext(loglevel=LogLevels.CRITICAL):  # GST main loop in thread (to process messages and display errors)\n",
    "    \n",
    "    # run both drone nd GCS MAV connections on this computer\n",
    "    with MAVCom(con1, source_system=111, loglevel=LogLevels.CRITICAL) as GCS_client:  # This normally runs on GCS\n",
    "        with MAVCom(con2, source_system=222, loglevel=LogLevels.CRITICAL) as UAV_server:  # This normally runs on drone\n",
    "\n",
    "            # add GCS manager\n",
    "            gcs: CameraClient = GCS_client.add_component(CameraClient(mav_type=mavlink.MAV_TYPE_GCS, source_component=11, loglevel=LogLevels.INFO))\n",
    "\n",
    "            server_config_dict = toml_load(config_dir() / f\"test_server_config.toml\")\n",
    "            print(server_config_dict)\n",
    "            # add 2 UAV cameras, This normally runs on drone\n",
    "            cam_0 = GSTCamera(server_config_dict, camera_dict=toml_load(config_dir() / \"test_cam_0.toml\"), loglevel=LogLevels.DEBUG)\n",
    "            cam_1 = GSTCamera(server_config_dict, camera_dict=toml_load(config_dir() / \"test_cam_1.toml\"), loglevel=LogLevels.DEBUG)\n",
    "\n",
    "            UAV_server.add_component(CameraServer(mav_type=mavlink.MAV_TYPE_CAMERA, source_component=mavlink.MAV_COMP_ID_CAMERA, camera=cam_0, loglevel=LogLevels.INFO))\n",
    "            UAV_server.add_component(CameraServer(mav_type=mavlink.MAV_TYPE_CAMERA, source_component=mavlink.MAV_COMP_ID_CAMERA2, camera=cam_1, loglevel=LogLevels.INFO))\n",
    "\n",
    "            # Wait till heartbeat found\n",
    "            ret = await gcs.wait_heartbeat(remote_mav_type=mavlink.MAV_TYPE_CAMERA, timeout=2)\n",
    "            print(f\"Camera Heartbeat {ret = }\")\n",
    "\n",
    "            # Camera manager GUI\n",
    "            gui = Gui(camera_client=gcs, gimbal_client=None)  # display GUI\n",
    "            t1 = asyncio.create_task(gui.find_cameras())   # find cameras from heartbeat info\n",
    "            t2 = asyncio.create_task(gui.run_gui())\n",
    "            \n",
    "            await asyncio.gather(t1, t2)\n",
    "            \n",
    "            # await asyncio.sleep(5)\n",
    "            \n",
    "            # try:\n",
    "            #     await asyncio.gather(t1, t3)\n",
    "            # except asyncio.CancelledError:\n",
    "            #     print(\"CancelledError\")\n",
    "            #     pass\n",
    "\n",
    "            cam_0.close()\n",
    "            cam_1.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "client_config_dict = toml_load(config_dir() / f\"client_config.toml\")\n",
    "if platform.processor() != 'aarch64':\n",
    "    client_config_dict['camera_udp_decoder'] = 'h264'  # on pc override as h264\n",
    "p = helpers.start_displays(client_config_dict, display_type='cv2')\n",
    "await main()\n",
    "p.terminate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Detail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a GST Camera\n",
    "Create physical camera object, as either a CV2Camera or GSTCamera\n",
    "The toml file contains the camera parameters, such as resolution, framerate, etc and also the gstreamer pipeline command to create the video streams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO |48.505| uav.GSTCamera   | gst_cam.py:354 | MainThread | MainProces | GSTCamera Started\u001b[0m\n",
      "\u001b[32mINFO |48.505| uav.GSTCamera   | gst_cam.py:580 | MainThread | MainProces | Setting camera_UDP_IP = 127.0.0.1\u001b[0m\n",
      "\u001b[32mINFO |48.506| uav.GSTCamera   | gst_cam.py:580 | MainThread | MainProces | Setting cam_0_UDP_port = 5000\u001b[0m\n",
      "\u001b[32mINFO |48.529| pygst.GstPipeli | gst_tools.:225 | MainThread | MainProces | Starting GstPipeline: videotestsrc pattern=ball is-live=true ! timeoverlay ! textoverlay text=\"Front\" valignment=top halignment=right font-desc=\"Sans, 18\" shaded-background=true ! capsfilter caps=video/x-raw,format=RGB,width=800,height=600,framerate=30/1 ! tee name=t t. ! queue ! videoscale  ! capsfilter caps=video/x-raw,format=RGB,width=400,height=300 ! videoconvert ! autovideosink t. ! interpipesink name=cam_0 \u001b[0m\n",
      "\u001b[37mDEBUG|48.529| pygst.GstPipeli | gst_tools.:229 | MainThread | MainProces | GstPipeline Setting pipeline state to PLAYING ... \u001b[0m\n",
      "\u001b[37mDEBUG|48.530| pygst.GstPipeli | gst_tools.:231 | MainThread | MainProces | GstPipeline Pipeline state set to PLAYING \u001b[0m\n",
      "\u001b[32mINFO |48.532| pygst.GstStream | gst_tools.:225 | MainThread | MainProces | Starting GstStreamUDP: interpipesrc listen-to=cam_0 is-live=true allow-renegotiation=true format=time ! valve name=myvalve drop=False  ! queue ! videorate drop-only=true skip-to-first=true ! video/x-raw,framerate=2/1 ! videoconvert ! x264enc tune=zerolatency noise-reduction=10000 bitrate=2048 speed-preset=superfast ! rtph264pay ! udpsink host=127.0.0.1 port=5000 sync=true\u001b[0m\n",
      "\u001b[37mDEBUG|48.532| pygst.GstStream | gst_tools.:229 | MainThread | MainProces | GstStreamUDP Setting pipeline state to PLAYING ... \u001b[0m\n",
      "\u001b[37mDEBUG|48.534| pygst.GstStream | gst_tools.:231 | MainThread | MainProces | GstStreamUDP Pipeline state set to PLAYING \u001b[0m\n",
      "\u001b[32mINFO |48.535| uav.GSTCamera   | gst_cam.py:748 | MainThread | MainProces | Video streaming pipeline \"gstreamer_udpsink\" created on port 5000\u001b[0m\n",
      "\u001b[37mDEBUG|48.635| pygst.GstStream | gst_tools.:265 | MainThread | MainProces | Valve \"myvalve\" state set to True\u001b[0m\n",
      "\u001b[32mINFO |48.636| uav.GSTCamera   | gst_cam.py:764 | MainThread | MainProces | Video streaming \"gstreamer_udpsink\" stopped (paused) on port 5000\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found config directory at: /home/john/PycharmProjects/UAV/config\n",
      "Found config directory at: /home/john/PycharmProjects/UAV/config\n",
      "John Doe                        \n"
     ]
    }
   ],
   "source": [
    "server_config_dict = toml_load(config_dir() / f\"test_server_config.toml\")\n",
    "cam_0 = GSTCamera(server_config_dict, camera_dict=toml_load(config_dir() / \"test_cam_0.toml\"), loglevel=LogLevels.DEBUG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Camera Configuration toml file printout\n",
    "```\n",
    "cam_name = 'cam_0'\n",
    "\n",
    "[camera_info]\n",
    "vendor_name = \"John Doe                   \"\n",
    "model_name = \"Fake Camera                  \"\n",
    "firmware_version = 1\n",
    "focal_length = 8.0\n",
    "sensor_size_h = 6.0\n",
    "sensor_size_v = 4.0\n",
    "resolution_h = 1920\n",
    "resolution_v = 1080\n",
    "lens_id = 0\n",
    "flags = 0\n",
    "cam_definition_version = 1\n",
    "cam_definition_uri = \"http://example.com/camera_definition.xml\"\n",
    "\n",
    "[camera_position]\n",
    "x = 0.0\n",
    "y = 0.0\n",
    "z = 0.0\n",
    "roll = 0.0\n",
    "pitch = 0.0\n",
    "yaw = 0.0\n",
    "\n",
    "[gstreamer_video_src]\n",
    "fps = 30   # Frames per second\n",
    "width = 800\n",
    "height = 600\n",
    "loglevel = 'DEBUG'   # todo add loglevel to all pipelines and to gst_utils\n",
    "\n",
    "pipeline = [\n",
    "    'videotestsrc pattern=ball is-live=true ! timeoverlay',\n",
    "    'textoverlay text=\"Front\" valignment=top halignment=right font-desc=\"Sans, 18\" shaded-background=true',\n",
    "    'capsfilter caps=video/x-raw,format=RGB,width={width},height={height},framerate={fps}/1',\n",
    "    'tee name=t',\n",
    "\n",
    "    \"t.\",\n",
    "    'queue', 'videoscale ', 'capsfilter caps=video/x-raw,format=RGB,width=400,height=300',\n",
    "    'videoconvert ! autovideosink',\n",
    "\n",
    "#    \"t.\",\n",
    "#    'queue leaky=2 ! intervideosink channel=channel_0  sync=false',\n",
    "#\n",
    "#    \"t.\",\n",
    "#    'queue leaky=2 ! intervideosink channel={cam_name}  sync=false',\n",
    "\n",
    "    \"t.\",\n",
    "    'interpipesink name={cam_name} ',\n",
    "]\n",
    "\n",
    "[gstreamer_udpsink]\n",
    "fps=2\n",
    "host = '*camera_UDP_IP*'     # overwrite with server_config.toml\n",
    "port = '*cam_0_UDP_port*'    # overwrite with server_config.toml\n",
    "pipeline = [\n",
    "\n",
    "    'interpipesrc listen-to={cam_name} is-live=true allow-renegotiation=true format=time',\n",
    "#    'queue max-size-buffers=1 leaky=downstream',\n",
    "    'valve name=myvalve drop=False ',\n",
    "    'queue',\n",
    "    'videorate drop-only=true skip-to-first=true ! video/x-raw,framerate={fps}/1',\n",
    "    'videoconvert',\n",
    "     'x264enc tune=zerolatency noise-reduction=10000 bitrate=2048 speed-preset=superfast',\n",
    "#    'x264enc tune=zerolatency',\n",
    "    'rtph264pay ! udpsink host={host} port={port} sync=true',\n",
    "    ]\n",
    "\n",
    "[gstreamer_jpg_filesink]\n",
    "fps = 10   # Frames per second * 10\n",
    "quality = 85\n",
    "filenames = '%03d.jpg'\n",
    "index = 0\n",
    "\n",
    "pipeline = [\n",
    "    'interpipesrc listen-to={cam_name} is-live=false allow-renegotiation=true format=time',\n",
    "    'queue',\n",
    "    'videorate drop-only=true skip-to-first=true ! video/x-raw,framerate={fps}/10',\n",
    "    'videoconvert ! video/x-raw, format=I420',\n",
    "    'jpegenc quality={quality}',  # Quality of encoding, default is 85\n",
    "    'multifilesink location={save_path}/{cam_name}/{filenames} max-files=10 index={index}',\n",
    "    ]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAVlink connections\n",
    " Create the client mavlink connection, this is mounted on the GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO |48.758| mavcom.MAVCom   | mavcom.py :386 | Thread-25  | MainProces | MAVLink Mav2: True, source_system: 111\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# for the client, we use the udpin connection, you can use serial as an option i.e \"/dev/ttyACM0\", \"/dev/ttyUSB0\"\n",
    "client = MAVCom(\"udpin:localhost:14445\", source_system=111, loglevel=LogLevels.INFO)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the server mavlink connection, this is mounted on the UAV companion computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO |48.871| mavcom.MAVCom   | mavcom.py :386 | Thread-26  | MainProces | MAVLink Mav2: True, source_system: 222\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# for the server, we use the udpout connection, you can use serial as an option  \"/dev/ttyUSB0\"\n",
    "server = MAVCom(\"udpout:localhost:14445\", source_system=222) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Camera\n",
    "Add the camera client to the client mavlink connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO |48.895| mavcom.CameraCl | basecompon:123 | MainThread | MainProces | Component Started self.source_component = 11, self.mav_type = 6, self.source_system = 111\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "cam = client.add_component(CameraClient(mav_type=mavlink.MAV_TYPE_GCS, source_component=11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the camera server to the server mavlink connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO |48.908| mavcom.CameraSe | basecompon:123 | MainThread | MainProces | Component Started self.source_component = 100, self.mav_type = 30, self.source_system = 222\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "<CameraServer>"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "server.add_component(CameraServer(mav_type=mavlink.MAV_TYPE_CAMERA, source_component=mavlink.MAV_COMP_ID_CAMERA, camera=cam_0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait for the heartbeat from the camera server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heartbeat received ret = (222, 100)\n"
     ]
    }
   ],
   "source": [
    "%autoawait asyncio\n",
    "async def doit():\n",
    "    ret = await cam.wait_heartbeat(remote_mav_type=mavlink.MAV_TYPE_CAMERA)\n",
    "    print(f\"Heartbeat received {ret = }\")\n",
    "await doit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the target system and component for the camera client\n",
    "and request camera information, storage information, camera capture status, and camera settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37mDEBUG|48.934| uav.GSTCamera   | gst_cam.py:273 | Thread-30  | MainProces | self.mav.srcSystem = 222 self.mav.srcComponent = 100\u001b[0m\n",
      "\u001b[37mDEBUG|48.935| uav.GSTCamera   | gst_cam.py:274 | Thread-30  | MainProces | camera_information_send self.camera_info = {'vendor_name': [74, 111, 104, 110, 32, 68, 111, 101, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32], 'model_name': [70, 97, 107, 101, 32, 67, 97, 109, 101, 114, 97, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32], 'firmware_version': 1, 'focal_length': 8.0, 'sensor_size_h': 6.0, 'sensor_size_v': 4.0, 'resolution_h': 1920, 'resolution_v': 1080, 'lens_id': 0, 'flags': 0, 'cam_definition_version': 1, 'cam_definition_uri': 'http://example.com/camera_definition.xml'} self.mav = <pymavlink.dialects.v20.ardupilotmega.MAVLink object>\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 MAVLINK_MSG_ID_CAMERA_INFORMATION CAMERA_INFORMATION {time_boot_ms : 220300, vendor_name : John Doe, model_name : Fake Camera, firmware_version : 1, focal_length : 8.0, sensor_size_h : 6.0, sensor_size_v : 4.0, resolution_h : 1920, resolution_v : 1080, lens_id : 0, flags : 0, cam_definition_version : 1, cam_definition_uri : http://example.com/camera_definition.xml, gimbal_device_id : 0}\n",
      "2 MAVLINK_MSG_ID_STORAGE_INFORMATION STORAGE_INFORMATION {time_boot_ms : 220401, storage_id : 0, storage_count : 1, status : 0, total_capacity : 100000000.0, used_capacity : 0.0, available_capacity : 100000000.0, read_speed : 0.0, write_speed : 0.0, type : 0, name : }\n",
      "3 MAVLINK_MSG_ID_CAMERA_CAPTURE_STATUS CAMERA_CAPTURE_STATUS {time_boot_ms : 220502, image_status : 0, video_status : 0, image_interval : 0.0, recording_time_ms : 0, available_capacity : 0.0, image_count : 0}\n",
      "4 MAVLINK_MSG_ID_CAMERA_SETTINGS CAMERA_SETTINGS {time_boot_ms : 220604, mode_id : 0, zoomLevel : 0.0, focusLevel : 0.0}\n"
     ]
    }
   ],
   "source": [
    "%autoawait asyncio\n",
    "async def doit():\n",
    "    msg = await cam.request_message(mavlink.MAVLINK_MSG_ID_CAMERA_INFORMATION, target_system=222, target_component=mavlink.MAV_COMP_ID_CAMERA)\n",
    "    print (f\"1 MAVLINK_MSG_ID_CAMERA_INFORMATION {msg }\")\n",
    "    msg = await cam.request_message(mavlink.MAVLINK_MSG_ID_STORAGE_INFORMATION, target_system=222, target_component=mavlink.MAV_COMP_ID_CAMERA)\n",
    "    print (f\"2 MAVLINK_MSG_ID_STORAGE_INFORMATION {msg }\")\n",
    "    msg = await cam.request_message(mavlink.MAVLINK_MSG_ID_CAMERA_CAPTURE_STATUS, target_system=222, target_component=mavlink.MAV_COMP_ID_CAMERA)\n",
    "    print (f\"3 MAVLINK_MSG_ID_CAMERA_CAPTURE_STATUS {msg }\")\n",
    "    msg = await cam.request_message(mavlink.MAVLINK_MSG_ID_CAMERA_SETTINGS, target_system=222, target_component=mavlink.MAV_COMP_ID_CAMERA)\n",
    "    print (f\"4 MAVLINK_MSG_ID_CAMERA_SETTINGS {msg }\")\n",
    "await doit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start an image capture seqeunce, \n",
    "and display the images as they arrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cam.image_start_capture(interval=0.1, count=10)\n",
    "# while cam_gst_1.capture_thread.is_alive():\n",
    "#     if cam_gst_1.last_image is not None:\n",
    "#         cv2.imshow('gst_src', cam_gst_1.last_image)\n",
    "#         cam_gst_1.last_image = None\n",
    "#     cv2.waitKey(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
